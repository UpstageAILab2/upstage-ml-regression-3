{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공통사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import gdown\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../data/train.csv'\n",
    "test_path  = '../../data/test.csv'\n",
    "dt = pd.read_csv(train_path)\n",
    "dt_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 구분을 위한 칼럼을 하나 만들어 줍니다.\n",
    "# 데이터를 동일하게 처리해주기 유용함.\n",
    "dt['is_test'] = 0\n",
    "dt_test['is_test'] = 1\n",
    "df = pd.concat([dt, dt_test])     # 하나의 데이터로 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 없어 보이는 columns 제거\n",
    "drop_col = ['부번', '계약일', 'k-전화번호', 'k-팩스번호', 'k-관리방식', 'k-복도유형', 'k-시행사', 'k-사용검사일-사용승인일', 'k-홈페이지', 'k-등록일자', 'k-수정일자', '고용보험관리번호', '경비비관리형태', '세대전기계약방법', '청소비관리형태', '기타/의무/임대/임의=1/2/3/4', '단지승인일', '사용허가여부', '관리비 업로드', '단지신청일', 'k-관리비부과면적', '주차대수', '건축면적', '해제사유발생일', '단지소개기존clob', 'k-135㎡초과', '중개사소재지', '등기신청일자']\n",
    "df.drop(drop_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['구'] = df['시군구'].apply(lambda x:x.split()[1])\n",
    "df['동'] = df['시군구'].apply(lambda x:x.split()[2])\n",
    "\n",
    "omg = ['용산구', '강남구', '서초구', '송파구', '성동구', '종로구']\n",
    "is_omg = []\n",
    "for x in df['구'].tolist():\n",
    "    if x in omg:\n",
    "        is_omg.append(1)\n",
    "    else:\n",
    "        is_omg.append(0)\n",
    "df['개비싸'] = is_omg\n",
    "# 이렇게 말고 '동' 을 분류하지 않아도 될듯       \n",
    "df.loc[~df['구'].isin(omg), '동'] = 'Unknown' \n",
    "\n",
    "del df['시군구']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 처럼 아무 의미도 갖지 않는 칼럼은 결측치와 같은 역할을 하므로, np.nan으로 채워 결측치로 인식되도록 합니다.\n",
    "df['거래유형'] = df['거래유형'].replace('-', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본번, 부번의 경우 float로 되어있지만 범주형 변수의 의미를 가지므로 object(string) 형태로 바꾸어주고 아래 작업을 진행하겠습니다.\n",
    "df['본번'] = df['본번'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['계약년'] = df['계약년월'].astype('str').map(lambda x : x[:4])\n",
    "df['계약월'] = df['계약년월'].astype('str').map(lambda x : x[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2017-12-01\n",
      "1   2017-12-01\n",
      "2   2017-12-01\n",
      "3   2018-01-01\n",
      "4   2018-01-01\n",
      "Name: 계약년월, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# 'time_col' 데이터를 문자열 형태로 변환\n",
    "df['계약년월'] = df['계약년월'].astype(str)\n",
    "# 문자열 형태 데이터를 datetime 형태로 변환\n",
    "df['계약년월'] = pd.to_datetime(df['계약년월'], format='%Y%m')\n",
    "# 변환 확인\n",
    "print(df['계약년월'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연속형 변수: ['전용면적(㎡)', '층', '건축년도', 'k-전체동수', 'k-전체세대수', 'k-연면적', 'k-주거전용면적', 'k-전용면적별세대현황(60㎡이하)', 'k-전용면적별세대현황(60㎡~85㎡이하)', 'k-85㎡~135㎡이하', '좌표X', '좌표Y', 'target', 'is_test', '개비싸']\n",
      "범주형 변수: ['번지', '본번', '아파트명', '계약년월', '도로명', '거래유형', 'k-단지분류(아파트,주상복합등등)', 'k-세대타입(분양형태)', 'k-난방방식', 'k-건설사(시공사)', '구', '동', '계약년', '계약월']\n"
     ]
    }
   ],
   "source": [
    "# 먼저, 연속형 변수와 범주형 변수를 위 info에 따라 분리해주겠습니다.\n",
    "continuous_columns = []\n",
    "categorical_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        continuous_columns.append(column)\n",
    "    else:\n",
    "        categorical_columns.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns)\n",
    "print(\"범주형 변수:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터를 어떻게 채워야 될지 모르겠음 -> 걍 빼.\n",
    "# 좌표X, 좌표Y 를 리니어로 채우는건 혼동을 줄 수 있는 데이터임\n",
    "df.drop(columns=['k-전체동수', 'k-전체세대수', 'k-연면적', 'k-주거전용면적', 'k-전용면적별세대현황(60㎡이하)', 'k-전용면적별세대현황(60㎡~85㎡이하)', 'k-85㎡~135㎡이하', '좌표X', '좌표Y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수에 대한 보간\n",
    "df[categorical_columns] = df[categorical_columns].fillna('NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1118822, 19) (9272, 19)\n"
     ]
    }
   ],
   "source": [
    "df_train = df.loc[df['is_test']==0, :]\n",
    "df_test = df.loc[df['is_test']==1, :]\n",
    "\n",
    "df_train.drop(['is_test'], axis=1, inplace=True)\n",
    "df_test.drop(['is_test'], axis=1, inplace=True)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_test의 target은 일단 0으로 임의로 채워주도록 하겠습니다.\n",
    "df_test['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연속형 변수: ['전용면적(㎡)', '층', '건축년도', 'target', '개비싸']\n",
      "범주형 변수: ['번지', '본번', '아파트명', '도로명', '거래유형', 'k-단지분류(아파트,주상복합등등)', 'k-세대타입(분양형태)', 'k-난방방식', 'k-건설사(시공사)', '구', '동', '계약년', '계약월']\n"
     ]
    }
   ],
   "source": [
    "# 파생변수 제작으로 추가된 변수들이 존재하기에, 다시한번 연속형과 범주형 칼럼을 분리해주겠습니다.\n",
    "continuous_columns_v2 = []\n",
    "categorical_columns_v2 = []\n",
    "\n",
    "for column in df_train.columns:\n",
    "    if column == '계약년월':\n",
    "        continue\n",
    "    if pd.api.types.is_numeric_dtype(df_train[column]):\n",
    "        continuous_columns_v2.append(column)\n",
    "    else:\n",
    "        categorical_columns_v2.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns_v2)\n",
    "print(\"범주형 변수:\", categorical_columns_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# 아래에서 범주형 변수들을 대상으로 레이블인코딩을 진행해 주겠습니다.\n",
    "\n",
    "# 각 변수에 대한 LabelEncoder를 저장할 딕셔너리\n",
    "label_encoders = {}\n",
    "\n",
    "# Implement Label Encoding\n",
    "for col in tqdm( categorical_columns_v2 ):\n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    # Label-Encoding을 fit\n",
    "    lbl.fit( df_train[col].astype(str) )\n",
    "    df_train[col] = lbl.transform(df_train[col].astype(str))\n",
    "    label_encoders[col] = lbl           # 나중에 후처리를 위해 레이블인코더를 저장해주겠습니다.\n",
    "\n",
    "    # Test 데이터에만 존재하는 새로 출현한 데이터를 신규 클래스로 추가해줍니다.\n",
    "    for label in np.unique(df_test[col]):\n",
    "      if label not in lbl.classes_: # unseen label 데이터인 경우\n",
    "        lbl.classes_ = np.append(lbl.classes_, label) # 미처리 시 ValueError발생하니 주의하세요!\n",
    "\n",
    "    df_test[col] = lbl.transform(df_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>번지</th>\n",
       "      <th>본번</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>전용면적(㎡)</th>\n",
       "      <th>계약년월</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>도로명</th>\n",
       "      <th>거래유형</th>\n",
       "      <th>k-단지분류(아파트,주상복합등등)</th>\n",
       "      <th>k-세대타입(분양형태)</th>\n",
       "      <th>k-난방방식</th>\n",
       "      <th>k-건설사(시공사)</th>\n",
       "      <th>target</th>\n",
       "      <th>구</th>\n",
       "      <th>동</th>\n",
       "      <th>개비싸</th>\n",
       "      <th>계약년</th>\n",
       "      <th>계약월</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>123500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>54.98</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     번지    본번  아파트명  전용면적(㎡)       계약년월  층  건축년도   도로명  거래유형  \\\n",
       "0  4732  1149   328    79.97 2017-12-01  3  1987  6176     0   \n",
       "1  4732  1149   328    79.97 2017-12-01  4  1987  6176     0   \n",
       "2  4732  1149   328    54.98 2017-12-01  5  1987  6176     0   \n",
       "3  4732  1149   328    79.97 2018-01-01  4  1987  6176     0   \n",
       "4  4732  1149   328    79.97 2018-01-01  2  1987  6176     0   \n",
       "\n",
       "   k-단지분류(아파트,주상복합등등)  k-세대타입(분양형태)  k-난방방식  k-건설사(시공사)    target  구  동  개비싸  \\\n",
       "0                   3             2       1         241  124000.0  0  3    1   \n",
       "1                   3             2       1         241  123500.0  0  3    1   \n",
       "2                   3             2       1         241   91500.0  0  3    1   \n",
       "3                   3             2       1         241  130000.0  0  3    1   \n",
       "4                   3             2       1         241  117000.0  0  3    1   \n",
       "\n",
       "   계약년  계약월  \n",
       "0   10   11  \n",
       "1   10   11  \n",
       "2   10   11  \n",
       "3   11    0  \n",
       "4   11    0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()        # 레이블인코딩이 된 모습입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gmnam.tistory.com/230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train.shape[1] == df_test.shape[1]          # train/test dataset의 shape이 같은지 확인해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['번지', '본번', '아파트명', '전용면적_㎡_', '계약년월', '층', '건축년도', '도로명', '거래유형',\n",
      "       'k_단지분류_아파트_주상복합등등_', 'k_세대타입_분양형태_', 'k_난방방식', 'k_건설사_시공사_', 'target',\n",
      "       '구', '동', '개비싸', '계약년', '계약월'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def preprocess_feature_name(feature_name):\n",
    "  \"\"\"특수 문자를 제거하고 소문자로 변환합니다.\"\"\"\n",
    "  feature_name = feature_name.replace(\"-\", \"_\")\n",
    "  feature_name = feature_name.replace(\",\", \"_\")\n",
    "  feature_name = feature_name.replace(\".\", \"_\")\n",
    "  feature_name = feature_name.replace(\"(\", \"_\")\n",
    "  feature_name = feature_name.replace(\")\", \"_\")\n",
    "  feature_name = feature_name.lower()\n",
    "  return feature_name\n",
    "\n",
    "def apply_preprocessed_feature_names(df_train):\n",
    "  \"\"\"데이터 프레임의 feature 이름을 수정합니다.\"\"\"\n",
    "  df_train.columns = [preprocess_feature_name(feature) for feature in df_train.columns]\n",
    "  return df_train\n",
    "\n",
    "# 데이터 프레임에 적용\n",
    "df_train = apply_preprocessed_feature_names(df_train.copy())\n",
    "df_test = apply_preprocessed_feature_names(df_test.copy())\n",
    "\n",
    "# 확인\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>번지</th>\n",
       "      <th>본번</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>전용면적_㎡_</th>\n",
       "      <th>계약년월</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>도로명</th>\n",
       "      <th>거래유형</th>\n",
       "      <th>k_단지분류_아파트_주상복합등등_</th>\n",
       "      <th>k_세대타입_분양형태_</th>\n",
       "      <th>k_난방방식</th>\n",
       "      <th>k_건설사_시공사_</th>\n",
       "      <th>target</th>\n",
       "      <th>구</th>\n",
       "      <th>동</th>\n",
       "      <th>개비싸</th>\n",
       "      <th>계약년</th>\n",
       "      <th>계약월</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>123500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>54.98</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4732</td>\n",
       "      <td>1149</td>\n",
       "      <td>328</td>\n",
       "      <td>79.97</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     번지    본번  아파트명  전용면적_㎡_       계약년월  층  건축년도   도로명  거래유형  \\\n",
       "0  4732  1149   328    79.97 2017-12-01  3  1987  6176     0   \n",
       "1  4732  1149   328    79.97 2017-12-01  4  1987  6176     0   \n",
       "2  4732  1149   328    54.98 2017-12-01  5  1987  6176     0   \n",
       "3  4732  1149   328    79.97 2018-01-01  4  1987  6176     0   \n",
       "4  4732  1149   328    79.97 2018-01-01  2  1987  6176     0   \n",
       "\n",
       "   k_단지분류_아파트_주상복합등등_  k_세대타입_분양형태_  k_난방방식  k_건설사_시공사_    target  구  동  개비싸  \\\n",
       "0                   3             2       1         241  124000.0  0  3    1   \n",
       "1                   3             2       1         241  123500.0  0  3    1   \n",
       "2                   3             2       1         241   91500.0  0  3    1   \n",
       "3                   3             2       1         241  130000.0  0  3    1   \n",
       "4                   3             2       1         241  117000.0  0  3    1   \n",
       "\n",
       "   계약년  계약월  \n",
       "0   10   11  \n",
       "1   10   11  \n",
       "2   10   11  \n",
       "3   11    0  \n",
       "4   11    0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout - Random\n",
    "y_train = df_train['target']\n",
    "X_train = df_train.drop(['target', '계약년월'], axis=1)\n",
    "\n",
    "holdout_random_X_train, holdout_random_X_val, holdout_random_y_train, holdout_random_y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1759\n",
      "[LightGBM] [Info] Number of data points in the train set: 895057, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 58000.483999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 27029.5\ttraining's l2: 7.30595e+08\tvalid_1's rmse: 27305.8\tvalid_1's l2: 7.45608e+08\n",
      "[20]\ttraining's rmse: 20590.9\ttraining's l2: 4.23986e+08\tvalid_1's rmse: 20889.8\tvalid_1's l2: 4.36385e+08\n",
      "[30]\ttraining's rmse: 17710.6\ttraining's l2: 3.13664e+08\tvalid_1's rmse: 18041.2\tvalid_1's l2: 3.25485e+08\n",
      "[40]\ttraining's rmse: 16163.6\ttraining's l2: 2.61261e+08\tvalid_1's rmse: 16501.7\tvalid_1's l2: 2.72308e+08\n",
      "[50]\ttraining's rmse: 15126.5\ttraining's l2: 2.2881e+08\tvalid_1's rmse: 15480.8\tvalid_1's l2: 2.39656e+08\n",
      "[60]\ttraining's rmse: 14424.6\ttraining's l2: 2.0807e+08\tvalid_1's rmse: 14783.9\tvalid_1's l2: 2.18564e+08\n",
      "[70]\ttraining's rmse: 13875.6\ttraining's l2: 1.92533e+08\tvalid_1's rmse: 14260.8\tvalid_1's l2: 2.03372e+08\n",
      "[80]\ttraining's rmse: 13412.7\ttraining's l2: 1.799e+08\tvalid_1's rmse: 13800.6\tvalid_1's l2: 1.90458e+08\n",
      "[90]\ttraining's rmse: 13061.3\ttraining's l2: 1.70597e+08\tvalid_1's rmse: 13465\tvalid_1's l2: 1.81306e+08\n",
      "[100]\ttraining's rmse: 12739.9\ttraining's l2: 1.62305e+08\tvalid_1's rmse: 13148.7\tvalid_1's l2: 1.72888e+08\n",
      "[110]\ttraining's rmse: 12431.8\ttraining's l2: 1.54549e+08\tvalid_1's rmse: 12847.2\tvalid_1's l2: 1.65051e+08\n",
      "[120]\ttraining's rmse: 12151.2\ttraining's l2: 1.47652e+08\tvalid_1's rmse: 12568.4\tvalid_1's l2: 1.57965e+08\n",
      "[130]\ttraining's rmse: 11911.4\ttraining's l2: 1.41882e+08\tvalid_1's rmse: 12335.4\tvalid_1's l2: 1.52163e+08\n",
      "[140]\ttraining's rmse: 11699.3\ttraining's l2: 1.36873e+08\tvalid_1's rmse: 12121.9\tvalid_1's l2: 1.4694e+08\n",
      "[150]\ttraining's rmse: 11493\ttraining's l2: 1.32089e+08\tvalid_1's rmse: 11917.6\tvalid_1's l2: 1.42028e+08\n",
      "[160]\ttraining's rmse: 11287.1\ttraining's l2: 1.27399e+08\tvalid_1's rmse: 11713.2\tvalid_1's l2: 1.37199e+08\n",
      "[170]\ttraining's rmse: 11118.1\ttraining's l2: 1.23612e+08\tvalid_1's rmse: 11544.5\tvalid_1's l2: 1.33275e+08\n",
      "[180]\ttraining's rmse: 10972.2\ttraining's l2: 1.2039e+08\tvalid_1's rmse: 11404.4\tvalid_1's l2: 1.30061e+08\n",
      "[190]\ttraining's rmse: 10828.7\ttraining's l2: 1.1726e+08\tvalid_1's rmse: 11265.9\tvalid_1's l2: 1.26921e+08\n",
      "[200]\ttraining's rmse: 10718.3\ttraining's l2: 1.14882e+08\tvalid_1's rmse: 11158\tvalid_1's l2: 1.24501e+08\n",
      "[210]\ttraining's rmse: 10604.9\ttraining's l2: 1.12463e+08\tvalid_1's rmse: 11045.2\tvalid_1's l2: 1.21996e+08\n",
      "[220]\ttraining's rmse: 10479.3\ttraining's l2: 1.09815e+08\tvalid_1's rmse: 10918\tvalid_1's l2: 1.19203e+08\n",
      "[230]\ttraining's rmse: 10373.1\ttraining's l2: 1.076e+08\tvalid_1's rmse: 10812.3\tvalid_1's l2: 1.16906e+08\n",
      "[240]\ttraining's rmse: 10279.6\ttraining's l2: 1.0567e+08\tvalid_1's rmse: 10722.8\tvalid_1's l2: 1.14977e+08\n",
      "[250]\ttraining's rmse: 10179.1\ttraining's l2: 1.03615e+08\tvalid_1's rmse: 10623.9\tvalid_1's l2: 1.12867e+08\n",
      "[260]\ttraining's rmse: 10085.9\ttraining's l2: 1.01725e+08\tvalid_1's rmse: 10530.8\tvalid_1's l2: 1.10897e+08\n",
      "[270]\ttraining's rmse: 9986\ttraining's l2: 9.97201e+07\tvalid_1's rmse: 10437.4\tvalid_1's l2: 1.08939e+08\n",
      "[280]\ttraining's rmse: 9893.13\ttraining's l2: 9.78741e+07\tvalid_1's rmse: 10347.5\tvalid_1's l2: 1.07071e+08\n",
      "[290]\ttraining's rmse: 9796.61\ttraining's l2: 9.59737e+07\tvalid_1's rmse: 10256\tvalid_1's l2: 1.05185e+08\n",
      "[300]\ttraining's rmse: 9705.91\ttraining's l2: 9.42047e+07\tvalid_1's rmse: 10169.3\tvalid_1's l2: 1.03415e+08\n",
      "[310]\ttraining's rmse: 9633.65\ttraining's l2: 9.28073e+07\tvalid_1's rmse: 10099.1\tvalid_1's l2: 1.01992e+08\n",
      "[320]\ttraining's rmse: 9564.07\ttraining's l2: 9.14715e+07\tvalid_1's rmse: 10034.8\tvalid_1's l2: 1.00698e+08\n",
      "[330]\ttraining's rmse: 9489.64\ttraining's l2: 9.00532e+07\tvalid_1's rmse: 9966.34\tvalid_1's l2: 9.93279e+07\n",
      "[340]\ttraining's rmse: 9425.68\ttraining's l2: 8.88435e+07\tvalid_1's rmse: 9905.39\tvalid_1's l2: 9.81167e+07\n",
      "[350]\ttraining's rmse: 9376.34\ttraining's l2: 8.79158e+07\tvalid_1's rmse: 9859.76\tvalid_1's l2: 9.72148e+07\n",
      "[360]\ttraining's rmse: 9300.18\ttraining's l2: 8.64933e+07\tvalid_1's rmse: 9790.11\tvalid_1's l2: 9.58464e+07\n",
      "[370]\ttraining's rmse: 9242.38\ttraining's l2: 8.54216e+07\tvalid_1's rmse: 9737.77\tvalid_1's l2: 9.48241e+07\n",
      "[380]\ttraining's rmse: 9175.59\ttraining's l2: 8.41915e+07\tvalid_1's rmse: 9678.21\tvalid_1's l2: 9.36677e+07\n",
      "[390]\ttraining's rmse: 9107.25\ttraining's l2: 8.2942e+07\tvalid_1's rmse: 9611.53\tvalid_1's l2: 9.23815e+07\n",
      "[400]\ttraining's rmse: 9048.47\ttraining's l2: 8.18748e+07\tvalid_1's rmse: 9556.73\tvalid_1's l2: 9.1331e+07\n",
      "[410]\ttraining's rmse: 8991.71\ttraining's l2: 8.08508e+07\tvalid_1's rmse: 9502.97\tvalid_1's l2: 9.03064e+07\n",
      "[420]\ttraining's rmse: 8929.21\ttraining's l2: 7.97308e+07\tvalid_1's rmse: 9446.54\tvalid_1's l2: 8.92371e+07\n",
      "[430]\ttraining's rmse: 8869.14\ttraining's l2: 7.86616e+07\tvalid_1's rmse: 9392.79\tvalid_1's l2: 8.82244e+07\n",
      "[440]\ttraining's rmse: 8804.1\ttraining's l2: 7.75122e+07\tvalid_1's rmse: 9332.06\tvalid_1's l2: 8.70873e+07\n",
      "[450]\ttraining's rmse: 8760.01\ttraining's l2: 7.67378e+07\tvalid_1's rmse: 9290.87\tvalid_1's l2: 8.63203e+07\n",
      "[460]\ttraining's rmse: 8708.38\ttraining's l2: 7.5836e+07\tvalid_1's rmse: 9236.86\tvalid_1's l2: 8.53196e+07\n",
      "[470]\ttraining's rmse: 8659.32\ttraining's l2: 7.49839e+07\tvalid_1's rmse: 9191.44\tvalid_1's l2: 8.44825e+07\n",
      "[480]\ttraining's rmse: 8613.22\ttraining's l2: 7.41876e+07\tvalid_1's rmse: 9149.08\tvalid_1's l2: 8.37057e+07\n",
      "[490]\ttraining's rmse: 8567.94\ttraining's l2: 7.34096e+07\tvalid_1's rmse: 9108.99\tvalid_1's l2: 8.29738e+07\n",
      "[500]\ttraining's rmse: 8525.77\ttraining's l2: 7.26888e+07\tvalid_1's rmse: 9074.45\tvalid_1's l2: 8.23457e+07\n",
      "[510]\ttraining's rmse: 8484.18\ttraining's l2: 7.19812e+07\tvalid_1's rmse: 9035.1\tvalid_1's l2: 8.1633e+07\n",
      "[520]\ttraining's rmse: 8451.24\ttraining's l2: 7.14235e+07\tvalid_1's rmse: 9009.17\tvalid_1's l2: 8.11651e+07\n",
      "[530]\ttraining's rmse: 8410.37\ttraining's l2: 7.07344e+07\tvalid_1's rmse: 8973.19\tvalid_1's l2: 8.05181e+07\n",
      "[540]\ttraining's rmse: 8370.26\ttraining's l2: 7.00612e+07\tvalid_1's rmse: 8937.02\tvalid_1's l2: 7.98703e+07\n",
      "[550]\ttraining's rmse: 8335.08\ttraining's l2: 6.94736e+07\tvalid_1's rmse: 8907.18\tvalid_1's l2: 7.93378e+07\n",
      "[560]\ttraining's rmse: 8294.71\ttraining's l2: 6.88022e+07\tvalid_1's rmse: 8871.65\tvalid_1's l2: 7.87061e+07\n",
      "[570]\ttraining's rmse: 8256.98\ttraining's l2: 6.81777e+07\tvalid_1's rmse: 8837.32\tvalid_1's l2: 7.80981e+07\n",
      "[580]\ttraining's rmse: 8220.36\ttraining's l2: 6.75744e+07\tvalid_1's rmse: 8804.05\tvalid_1's l2: 7.75113e+07\n",
      "[590]\ttraining's rmse: 8185.88\ttraining's l2: 6.70087e+07\tvalid_1's rmse: 8775.4\tvalid_1's l2: 7.70076e+07\n",
      "[600]\ttraining's rmse: 8151.19\ttraining's l2: 6.64419e+07\tvalid_1's rmse: 8745.32\tvalid_1's l2: 7.64806e+07\n",
      "[610]\ttraining's rmse: 8117.83\ttraining's l2: 6.58992e+07\tvalid_1's rmse: 8715.82\tvalid_1's l2: 7.59655e+07\n",
      "[620]\ttraining's rmse: 8089.32\ttraining's l2: 6.54371e+07\tvalid_1's rmse: 8692.06\tvalid_1's l2: 7.55518e+07\n",
      "[630]\ttraining's rmse: 8053.46\ttraining's l2: 6.48582e+07\tvalid_1's rmse: 8655.1\tvalid_1's l2: 7.49108e+07\n",
      "[640]\ttraining's rmse: 8023.67\ttraining's l2: 6.43792e+07\tvalid_1's rmse: 8629.55\tvalid_1's l2: 7.44691e+07\n",
      "[650]\ttraining's rmse: 7993.83\ttraining's l2: 6.39014e+07\tvalid_1's rmse: 8605.14\tvalid_1's l2: 7.40484e+07\n",
      "[660]\ttraining's rmse: 7963.1\ttraining's l2: 6.34109e+07\tvalid_1's rmse: 8577.89\tvalid_1's l2: 7.35802e+07\n",
      "[670]\ttraining's rmse: 7928.14\ttraining's l2: 6.28553e+07\tvalid_1's rmse: 8542.58\tvalid_1's l2: 7.29756e+07\n",
      "[680]\ttraining's rmse: 7897.46\ttraining's l2: 6.23699e+07\tvalid_1's rmse: 8516.47\tvalid_1's l2: 7.25303e+07\n",
      "[690]\ttraining's rmse: 7868.4\ttraining's l2: 6.19117e+07\tvalid_1's rmse: 8489.29\tvalid_1's l2: 7.2068e+07\n",
      "[700]\ttraining's rmse: 7829.47\ttraining's l2: 6.13006e+07\tvalid_1's rmse: 8454.15\tvalid_1's l2: 7.14726e+07\n",
      "[710]\ttraining's rmse: 7804.46\ttraining's l2: 6.09095e+07\tvalid_1's rmse: 8431.77\tvalid_1's l2: 7.10947e+07\n",
      "[720]\ttraining's rmse: 7777.08\ttraining's l2: 6.04829e+07\tvalid_1's rmse: 8408.08\tvalid_1's l2: 7.06958e+07\n",
      "[730]\ttraining's rmse: 7747.71\ttraining's l2: 6.00271e+07\tvalid_1's rmse: 8380.85\tvalid_1's l2: 7.02386e+07\n",
      "[740]\ttraining's rmse: 7723.21\ttraining's l2: 5.9648e+07\tvalid_1's rmse: 8359.54\tvalid_1's l2: 6.9882e+07\n",
      "[750]\ttraining's rmse: 7695.27\ttraining's l2: 5.92172e+07\tvalid_1's rmse: 8335.49\tvalid_1's l2: 6.94803e+07\n",
      "[760]\ttraining's rmse: 7670.71\ttraining's l2: 5.88398e+07\tvalid_1's rmse: 8313.08\tvalid_1's l2: 6.91072e+07\n",
      "[770]\ttraining's rmse: 7646.32\ttraining's l2: 5.84662e+07\tvalid_1's rmse: 8290.08\tvalid_1's l2: 6.87254e+07\n",
      "[780]\ttraining's rmse: 7622.02\ttraining's l2: 5.80951e+07\tvalid_1's rmse: 8270.02\tvalid_1's l2: 6.83932e+07\n",
      "[790]\ttraining's rmse: 7595.82\ttraining's l2: 5.76964e+07\tvalid_1's rmse: 8246.43\tvalid_1's l2: 6.80036e+07\n",
      "[800]\ttraining's rmse: 7574.35\ttraining's l2: 5.73708e+07\tvalid_1's rmse: 8227.33\tvalid_1's l2: 6.76889e+07\n",
      "[810]\ttraining's rmse: 7545.56\ttraining's l2: 5.69354e+07\tvalid_1's rmse: 8202.3\tvalid_1's l2: 6.72777e+07\n",
      "[820]\ttraining's rmse: 7524.21\ttraining's l2: 5.66137e+07\tvalid_1's rmse: 8186.22\tvalid_1's l2: 6.70142e+07\n",
      "[830]\ttraining's rmse: 7494.78\ttraining's l2: 5.61718e+07\tvalid_1's rmse: 8161.15\tvalid_1's l2: 6.66044e+07\n",
      "[840]\ttraining's rmse: 7474.29\ttraining's l2: 5.58651e+07\tvalid_1's rmse: 8140.67\tvalid_1's l2: 6.62706e+07\n",
      "[850]\ttraining's rmse: 7449.7\ttraining's l2: 5.54981e+07\tvalid_1's rmse: 8119.78\tvalid_1's l2: 6.59309e+07\n",
      "[860]\ttraining's rmse: 7430.82\ttraining's l2: 5.52171e+07\tvalid_1's rmse: 8103.4\tvalid_1's l2: 6.56651e+07\n",
      "[870]\ttraining's rmse: 7407.37\ttraining's l2: 5.48691e+07\tvalid_1's rmse: 8084.14\tvalid_1's l2: 6.53533e+07\n",
      "[880]\ttraining's rmse: 7381.12\ttraining's l2: 5.44809e+07\tvalid_1's rmse: 8061.08\tvalid_1's l2: 6.49809e+07\n",
      "[890]\ttraining's rmse: 7349.55\ttraining's l2: 5.40158e+07\tvalid_1's rmse: 8034.24\tvalid_1's l2: 6.4549e+07\n",
      "[900]\ttraining's rmse: 7328.39\ttraining's l2: 5.37054e+07\tvalid_1's rmse: 8016.05\tvalid_1's l2: 6.42571e+07\n",
      "[910]\ttraining's rmse: 7306.39\ttraining's l2: 5.33833e+07\tvalid_1's rmse: 7997.59\tvalid_1's l2: 6.39614e+07\n",
      "[920]\ttraining's rmse: 7282.14\ttraining's l2: 5.30295e+07\tvalid_1's rmse: 7977.21\tvalid_1's l2: 6.36358e+07\n",
      "[930]\ttraining's rmse: 7262.73\ttraining's l2: 5.27473e+07\tvalid_1's rmse: 7960.62\tvalid_1's l2: 6.33715e+07\n",
      "[940]\ttraining's rmse: 7235.72\ttraining's l2: 5.23556e+07\tvalid_1's rmse: 7935.23\tvalid_1's l2: 6.29679e+07\n",
      "[950]\ttraining's rmse: 7217.68\ttraining's l2: 5.20949e+07\tvalid_1's rmse: 7920.06\tvalid_1's l2: 6.27274e+07\n",
      "[960]\ttraining's rmse: 7199.19\ttraining's l2: 5.18283e+07\tvalid_1's rmse: 7904.26\tvalid_1's l2: 6.24773e+07\n",
      "[970]\ttraining's rmse: 7181.97\ttraining's l2: 5.15807e+07\tvalid_1's rmse: 7888.43\tvalid_1's l2: 6.22274e+07\n",
      "[980]\ttraining's rmse: 7162.77\ttraining's l2: 5.13053e+07\tvalid_1's rmse: 7873.69\tvalid_1's l2: 6.19949e+07\n",
      "[990]\ttraining's rmse: 7147.9\ttraining's l2: 5.10925e+07\tvalid_1's rmse: 7861.31\tvalid_1's l2: 6.18002e+07\n",
      "[1000]\ttraining's rmse: 7129.75\ttraining's l2: 5.08333e+07\tvalid_1's rmse: 7848.15\tvalid_1's l2: 6.15935e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 7129.75\ttraining's l2: 5.08333e+07\tvalid_1's rmse: 7848.15\tvalid_1's l2: 6.15935e+07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_estimators=1000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMRegressor(n_estimators=1000)\n",
    "gbm.fit(holdout_random_X_train, holdout_random_y_train,\n",
    "        eval_set=[(holdout_random_X_train, holdout_random_y_train), (holdout_random_X_val, holdout_random_y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10),\n",
    "                   lgb.log_evaluation(period=10, show_stdv=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 431 ms, sys: 0 ns, total: 431 ms\n",
      "Wall time: 52.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = df_test.drop(['target', '계약년월'], axis=1)\n",
    "\n",
    "# Test dataset에 대한 inference를 진행합니다.\n",
    "real_test_pred = gbm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 예측한 예측값들을 저장합니다.\n",
    "preds_df = pd.DataFrame(real_test_pred.astype(int), columns=[\"target\"])\n",
    "preds_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout - 시간순서\n",
    "y_train = df_train['target']\n",
    "X_train = df_train.drop(['target'], axis=1)\n",
    "\n",
    "# 'date' 기준으로 데이터 정렬\n",
    "df_train = df_train.sort_values('계약년월')\n",
    "\n",
    "# 전체 데이터 길이의 20%를 검증 세트 크기로 사용\n",
    "validation_size = int(len(df_train) * 0.2)\n",
    "\n",
    "# 훈련 세트와 검증 세트로 분할\n",
    "train_df = df_train[:-validation_size]\n",
    "validation_df = df_train[-validation_size:]\n",
    "\n",
    "holdout_X_train = train_df.drop(['target'], axis=1)\n",
    "holdout_y_train = train_df['target']\n",
    "\n",
    "holdout_X_val = validation_df.drop(['target'], axis=1)\n",
    "holdout_y_val = validation_df['target']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Date Range :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timestamp('2007-01-01 00:00:00'),\n",
       " Timestamp('2007-01-01 00:00:00'),\n",
       " Timestamp('2007-01-01 00:00:00'),\n",
       " Timestamp('2007-01-01 00:00:00'),\n",
       " Timestamp('2007-01-01 00:00:00')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid set Date Range :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Train set Date Range :\")\n",
    "display(holdout_X_train['계약년월'].sort_values(ascending=True).head().to_list())\n",
    "print('...')\n",
    "display(holdout_X_train['계약년월'].sort_values(ascending=False).head().to_list())\n",
    "\n",
    "print(f\"Valid set Date Range :\")\n",
    "display(holdout_X_val['계약년월'].sort_values(ascending=True).head().to_list())\n",
    "print('...')\n",
    "display(holdout_X_val['계약년월'].sort_values(ascending=False).head().to_list())\n",
    "\n",
    "# 이제 train_df와 validation_df를 사용하여 모델 훈련 및 검증을 진행할 수 있습니다.\n",
    "del holdout_X_train['계약년월']\n",
    "del holdout_X_val['계약년월']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1745\n",
      "[LightGBM] [Info] Number of data points in the train set: 895058, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 49879.244612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 20658.3\ttraining's l2: 4.26764e+08\tvalid_1's rmse: 58851.1\tvalid_1's l2: 3.46346e+09\n",
      "[20]\ttraining's rmse: 15733.8\ttraining's l2: 2.47554e+08\tvalid_1's rmse: 51159.1\tvalid_1's l2: 2.61725e+09\n",
      "[30]\ttraining's rmse: 13670.6\ttraining's l2: 1.86886e+08\tvalid_1's rmse: 46216.5\tvalid_1's l2: 2.13597e+09\n",
      "[40]\ttraining's rmse: 12551.4\ttraining's l2: 1.57539e+08\tvalid_1's rmse: 43187.3\tvalid_1's l2: 1.86514e+09\n",
      "[50]\ttraining's rmse: 11796.4\ttraining's l2: 1.39154e+08\tvalid_1's rmse: 41033.7\tvalid_1's l2: 1.68377e+09\n",
      "[60]\ttraining's rmse: 11265.1\ttraining's l2: 1.26903e+08\tvalid_1's rmse: 39831.8\tvalid_1's l2: 1.58657e+09\n",
      "[70]\ttraining's rmse: 10865.3\ttraining's l2: 1.18055e+08\tvalid_1's rmse: 39047.6\tvalid_1's l2: 1.52471e+09\n",
      "[80]\ttraining's rmse: 10486.5\ttraining's l2: 1.09967e+08\tvalid_1's rmse: 38135\tvalid_1's l2: 1.45428e+09\n",
      "[90]\ttraining's rmse: 10178\ttraining's l2: 1.03591e+08\tvalid_1's rmse: 37678.1\tvalid_1's l2: 1.41964e+09\n",
      "[100]\ttraining's rmse: 9879.07\ttraining's l2: 9.7596e+07\tvalid_1's rmse: 37114.3\tvalid_1's l2: 1.37747e+09\n",
      "[110]\ttraining's rmse: 9656.55\ttraining's l2: 9.3249e+07\tvalid_1's rmse: 36844.9\tvalid_1's l2: 1.35755e+09\n",
      "[120]\ttraining's rmse: 9466.69\ttraining's l2: 8.96182e+07\tvalid_1's rmse: 36442.3\tvalid_1's l2: 1.32804e+09\n",
      "[130]\ttraining's rmse: 9261.58\ttraining's l2: 8.57768e+07\tvalid_1's rmse: 36197\tvalid_1's l2: 1.31022e+09\n",
      "[140]\ttraining's rmse: 9081.38\ttraining's l2: 8.24714e+07\tvalid_1's rmse: 35915.4\tvalid_1's l2: 1.28992e+09\n",
      "[150]\ttraining's rmse: 8902.99\ttraining's l2: 7.92632e+07\tvalid_1's rmse: 35632.3\tvalid_1's l2: 1.26966e+09\n",
      "[160]\ttraining's rmse: 8753.89\ttraining's l2: 7.66306e+07\tvalid_1's rmse: 35399.3\tvalid_1's l2: 1.25311e+09\n",
      "[170]\ttraining's rmse: 8629.76\ttraining's l2: 7.44728e+07\tvalid_1's rmse: 35268.1\tvalid_1's l2: 1.24384e+09\n",
      "[180]\ttraining's rmse: 8513.93\ttraining's l2: 7.2487e+07\tvalid_1's rmse: 35061.9\tvalid_1's l2: 1.22934e+09\n",
      "[190]\ttraining's rmse: 8412.88\ttraining's l2: 7.07765e+07\tvalid_1's rmse: 34805.4\tvalid_1's l2: 1.21141e+09\n",
      "[200]\ttraining's rmse: 8317.46\ttraining's l2: 6.91801e+07\tvalid_1's rmse: 34629.8\tvalid_1's l2: 1.19922e+09\n",
      "[210]\ttraining's rmse: 8214.97\ttraining's l2: 6.74858e+07\tvalid_1's rmse: 34479.4\tvalid_1's l2: 1.18883e+09\n",
      "[220]\ttraining's rmse: 8132.96\ttraining's l2: 6.61451e+07\tvalid_1's rmse: 34377.2\tvalid_1's l2: 1.18179e+09\n",
      "[230]\ttraining's rmse: 8047.42\ttraining's l2: 6.47609e+07\tvalid_1's rmse: 34275.4\tvalid_1's l2: 1.1748e+09\n",
      "[240]\ttraining's rmse: 7958.36\ttraining's l2: 6.33355e+07\tvalid_1's rmse: 34157.8\tvalid_1's l2: 1.16676e+09\n",
      "[250]\ttraining's rmse: 7885.92\ttraining's l2: 6.21877e+07\tvalid_1's rmse: 33934\tvalid_1's l2: 1.15151e+09\n",
      "[260]\ttraining's rmse: 7833.8\ttraining's l2: 6.13685e+07\tvalid_1's rmse: 33873.3\tvalid_1's l2: 1.1474e+09\n",
      "[270]\ttraining's rmse: 7773.39\ttraining's l2: 6.04255e+07\tvalid_1's rmse: 33822.9\tvalid_1's l2: 1.14399e+09\n",
      "[280]\ttraining's rmse: 7710.19\ttraining's l2: 5.94471e+07\tvalid_1's rmse: 33721\tvalid_1's l2: 1.1371e+09\n",
      "[290]\ttraining's rmse: 7647.53\ttraining's l2: 5.84847e+07\tvalid_1's rmse: 33624.4\tvalid_1's l2: 1.1306e+09\n",
      "[300]\ttraining's rmse: 7597.29\ttraining's l2: 5.77188e+07\tvalid_1's rmse: 33476.4\tvalid_1's l2: 1.12067e+09\n",
      "[310]\ttraining's rmse: 7529.88\ttraining's l2: 5.66992e+07\tvalid_1's rmse: 33445.4\tvalid_1's l2: 1.11859e+09\n",
      "[320]\ttraining's rmse: 7470.6\ttraining's l2: 5.58099e+07\tvalid_1's rmse: 33384\tvalid_1's l2: 1.11449e+09\n",
      "[330]\ttraining's rmse: 7423.04\ttraining's l2: 5.51015e+07\tvalid_1's rmse: 33229.8\tvalid_1's l2: 1.10422e+09\n",
      "[340]\ttraining's rmse: 7374.77\ttraining's l2: 5.43872e+07\tvalid_1's rmse: 33182.9\tvalid_1's l2: 1.10111e+09\n",
      "[350]\ttraining's rmse: 7317.11\ttraining's l2: 5.35402e+07\tvalid_1's rmse: 33087.1\tvalid_1's l2: 1.09476e+09\n",
      "[360]\ttraining's rmse: 7270.87\ttraining's l2: 5.28655e+07\tvalid_1's rmse: 33040.3\tvalid_1's l2: 1.09166e+09\n",
      "[370]\ttraining's rmse: 7218.01\ttraining's l2: 5.20996e+07\tvalid_1's rmse: 32963.1\tvalid_1's l2: 1.08656e+09\n",
      "[380]\ttraining's rmse: 7177.52\ttraining's l2: 5.15168e+07\tvalid_1's rmse: 32933.9\tvalid_1's l2: 1.08464e+09\n",
      "[390]\ttraining's rmse: 7140.49\ttraining's l2: 5.09866e+07\tvalid_1's rmse: 32853.6\tvalid_1's l2: 1.07936e+09\n",
      "[400]\ttraining's rmse: 7098.19\ttraining's l2: 5.03842e+07\tvalid_1's rmse: 32737.7\tvalid_1's l2: 1.07176e+09\n",
      "[410]\ttraining's rmse: 7051.44\ttraining's l2: 4.97228e+07\tvalid_1's rmse: 32695.2\tvalid_1's l2: 1.06897e+09\n",
      "[420]\ttraining's rmse: 7012.58\ttraining's l2: 4.91763e+07\tvalid_1's rmse: 32642\tvalid_1's l2: 1.0655e+09\n",
      "[430]\ttraining's rmse: 6969.86\ttraining's l2: 4.85789e+07\tvalid_1's rmse: 32614.5\tvalid_1's l2: 1.0637e+09\n",
      "[440]\ttraining's rmse: 6926.24\ttraining's l2: 4.79728e+07\tvalid_1's rmse: 32569.3\tvalid_1's l2: 1.06076e+09\n",
      "[450]\ttraining's rmse: 6888.3\ttraining's l2: 4.74486e+07\tvalid_1's rmse: 32480.5\tvalid_1's l2: 1.05499e+09\n",
      "[460]\ttraining's rmse: 6854.24\ttraining's l2: 4.69806e+07\tvalid_1's rmse: 32440.1\tvalid_1's l2: 1.05236e+09\n",
      "[470]\ttraining's rmse: 6820.18\ttraining's l2: 4.65149e+07\tvalid_1's rmse: 32398.4\tvalid_1's l2: 1.04965e+09\n",
      "[480]\ttraining's rmse: 6789.53\ttraining's l2: 4.60977e+07\tvalid_1's rmse: 32351.8\tvalid_1's l2: 1.04664e+09\n",
      "[490]\ttraining's rmse: 6754.79\ttraining's l2: 4.56272e+07\tvalid_1's rmse: 32237.9\tvalid_1's l2: 1.03928e+09\n",
      "[500]\ttraining's rmse: 6723.01\ttraining's l2: 4.51989e+07\tvalid_1's rmse: 32198.7\tvalid_1's l2: 1.03676e+09\n",
      "[510]\ttraining's rmse: 6681.9\ttraining's l2: 4.46478e+07\tvalid_1's rmse: 32118.4\tvalid_1's l2: 1.03159e+09\n",
      "[520]\ttraining's rmse: 6648.31\ttraining's l2: 4.42001e+07\tvalid_1's rmse: 32091.9\tvalid_1's l2: 1.02989e+09\n",
      "[530]\ttraining's rmse: 6629.52\ttraining's l2: 4.39506e+07\tvalid_1's rmse: 32048.6\tvalid_1's l2: 1.02711e+09\n",
      "[540]\ttraining's rmse: 6595.67\ttraining's l2: 4.35029e+07\tvalid_1's rmse: 32018.7\tvalid_1's l2: 1.0252e+09\n",
      "[550]\ttraining's rmse: 6569.6\ttraining's l2: 4.31597e+07\tvalid_1's rmse: 31975.9\tvalid_1's l2: 1.02246e+09\n",
      "[560]\ttraining's rmse: 6536.85\ttraining's l2: 4.27305e+07\tvalid_1's rmse: 31943.3\tvalid_1's l2: 1.02037e+09\n",
      "[570]\ttraining's rmse: 6513.56\ttraining's l2: 4.24265e+07\tvalid_1's rmse: 31907.9\tvalid_1's l2: 1.01811e+09\n",
      "[580]\ttraining's rmse: 6481.27\ttraining's l2: 4.20069e+07\tvalid_1's rmse: 31893.2\tvalid_1's l2: 1.01717e+09\n",
      "[590]\ttraining's rmse: 6456.24\ttraining's l2: 4.16831e+07\tvalid_1's rmse: 31822.5\tvalid_1's l2: 1.01267e+09\n",
      "[600]\ttraining's rmse: 6429.09\ttraining's l2: 4.13332e+07\tvalid_1's rmse: 31789.8\tvalid_1's l2: 1.01059e+09\n",
      "[610]\ttraining's rmse: 6398.5\ttraining's l2: 4.09408e+07\tvalid_1's rmse: 31759.4\tvalid_1's l2: 1.00866e+09\n",
      "[620]\ttraining's rmse: 6374.6\ttraining's l2: 4.06355e+07\tvalid_1's rmse: 31701.1\tvalid_1's l2: 1.00496e+09\n",
      "[630]\ttraining's rmse: 6352.15\ttraining's l2: 4.03498e+07\tvalid_1's rmse: 31680.9\tvalid_1's l2: 1.00368e+09\n",
      "[640]\ttraining's rmse: 6333.48\ttraining's l2: 4.0113e+07\tvalid_1's rmse: 31659.4\tvalid_1's l2: 1.00232e+09\n",
      "[650]\ttraining's rmse: 6303.17\ttraining's l2: 3.973e+07\tvalid_1's rmse: 31609.8\tvalid_1's l2: 9.99181e+08\n",
      "[660]\ttraining's rmse: 6276.19\ttraining's l2: 3.93906e+07\tvalid_1's rmse: 31621.5\tvalid_1's l2: 9.99921e+08\n",
      "[670]\ttraining's rmse: 6257.47\ttraining's l2: 3.91559e+07\tvalid_1's rmse: 31586.6\tvalid_1's l2: 9.97713e+08\n",
      "[680]\ttraining's rmse: 6222.89\ttraining's l2: 3.87244e+07\tvalid_1's rmse: 31553.8\tvalid_1's l2: 9.95645e+08\n",
      "[690]\ttraining's rmse: 6200.15\ttraining's l2: 3.84419e+07\tvalid_1's rmse: 31545.5\tvalid_1's l2: 9.95121e+08\n",
      "[700]\ttraining's rmse: 6182.5\ttraining's l2: 3.82232e+07\tvalid_1's rmse: 31527.8\tvalid_1's l2: 9.94004e+08\n",
      "[710]\ttraining's rmse: 6154.51\ttraining's l2: 3.7878e+07\tvalid_1's rmse: 31542.2\tvalid_1's l2: 9.9491e+08\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's rmse: 6177.29\ttraining's l2: 3.81589e+07\tvalid_1's rmse: 31525.4\tvalid_1's l2: 9.9385e+08\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_estimators=1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMRegressor(n_estimators=1000)\n",
    "gbm.fit(holdout_X_train, holdout_y_train,\n",
    "        eval_set=[(holdout_X_train, holdout_y_train), (holdout_X_val, holdout_y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10),\n",
    "                   lgb.log_evaluation(period=10, show_stdv=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 401 ms, sys: 352 µs, total: 402 ms\n",
      "Wall time: 48.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = df_test.drop(['target', '계약년월'], axis=1)\n",
    "\n",
    "# Test dataset에 대한 inference를 진행합니다.\n",
    "real_test_pred = gbm.predict(X_test)\n",
    "\n",
    "# 앞서 예측한 예측값들을 저장합니다.\n",
    "preds_df = pd.DataFrame(real_test_pred.astype(int), columns=[\"target\"])\n",
    "preds_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- holdout 에서 시간순서로 했을 때 rmse 가 엄청나게 오름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
