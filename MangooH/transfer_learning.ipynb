{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score: 19447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import gdown\n",
    "import joblib\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold, TimeSeriesSplit\n",
    "import lightgbm as lgb\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# 코드 셀 실행 후 경고를 무시\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../data/train.csv'\n",
    "test_path  = '../../data/test.csv'\n",
    "dt_train = pd.read_csv(train_path)\n",
    "dt_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 구분을 위한 칼럼을 하나 만들어 줍니다.\n",
    "dt_train['is_test'] = 0\n",
    "dt_test['is_test'] = 1\n",
    "df = pd.concat([dt_train, dt_test])     # 하나의 데이터로 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_public'] = df[\"k-전용면적별세대현황(60㎡이하)\"].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['구'] = df['시군구'].map(lambda x : x.split()[1])\n",
    "df['동'] = df['시군구'].map(lambda x : x.split()[2])\n",
    "del df['시군구']\n",
    "\n",
    "mean_val_by_gu = df.groupby(\"구\")[\"target\"].mean().sort_values(ascending=False)\n",
    "mean_val_by_dong = df.groupby(\"동\")[\"target\"].mean().sort_values(ascending=False)\n",
    "std_val_by_gu = df.groupby(\"구\")[\"target\"].std().sort_values(ascending=False)\n",
    "std_val_by_dong = df.groupby(\"동\")[\"target\"].std().sort_values(ascending=False)\n",
    "\n",
    "order1_mean_gu = mean_val_by_gu.index.tolist()\n",
    "order2_mean_dong = mean_val_by_dong.index.tolist()\n",
    "order3_std_gu = std_val_by_gu.index.tolist()\n",
    "order4_std_dong = std_val_by_dong.index.tolist()\n",
    "\n",
    "# Create a dictionary to map district names to their corresponding label encoded values\n",
    "gu_mapping1 = {district: label for label, district in enumerate(order1_mean_gu)}\n",
    "gu_mapping2 = {district: label for label, district in enumerate(order3_std_gu)}\n",
    "dong_mapping1 = {dong: label for label, dong in enumerate(order2_mean_dong)}\n",
    "dong_mapping2 = {dong: label for label, dong in enumerate(order4_std_dong)}\n",
    "\n",
    "df['구_encoded'] = df[\"구\"].map(gu_mapping1)\n",
    "df['구_std'] = df[\"구\"].map(gu_mapping2)\n",
    "df['동_encoded'] = df[\"동\"].map(dong_mapping1)\n",
    "df['동_std'] = df[\"동\"].map(dong_mapping2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['계약년'] = df['계약년월'].astype('str').map(lambda x : x[:4]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['번지', '본번', '부번', '계약일', 'k-전화번호', 'k-팩스번호', 'k-관리방식', 'k-복도유형', 'k-시행사', 'k-사용검사일-사용승인일', 'k-홈페이지', 'k-등록일자', 'k-수정일자', '고용보험관리번호', '경비비관리형태', '세대전기계약방법', '청소비관리형태', '기타/의무/임대/임의=1/2/3/4', '단지승인일', '사용허가여부', '관리비 업로드', '단지신청일', 'k-관리비부과면적', '주차대수', '건축면적', '해제사유발생일', '단지소개기존clob', 'k-135㎡초과', '중개사소재지', '등기신청일자', '거래유형', 'k-전체동수', 'k-전체세대수', 'k-연면적', 'k-주거전용면적', 'k-전용면적별세대현황(60㎡이하)', 'k-전용면적별세대현황(60㎡~85㎡이하)', 'k-85㎡~135㎡이하', '좌표X', '좌표Y', 'k-단지분류(아파트,주상복합등등)', 'k-세대타입(분양형태)', 'k-난방방식','k-건설사(시공사)', '계약년월']\n",
    "df.drop(drop_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_df(df):\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['col_name'] = df.columns\n",
    "    \n",
    "\n",
    "    for i in range(len(df.columns)):\n",
    "        x = df.iloc[:, i]\n",
    "        temp_df.loc[i, 'data_type'] = x.dtype\n",
    "        temp_df.loc[i, 'have_null'] = any(x.isna())\n",
    "        temp_df.loc[i, 'null_count'] = x.isna().sum()\n",
    "        temp_df.loc[i, 'null_ratio'] = x.isna().sum() / x.shape[0]\n",
    "        temp_df.loc[i, 'nunique'] = x.nunique()\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연속형 변수: ['전용면적(㎡)', '층', '건축년도', 'target', 'is_test', 'is_public', '구_encoded', '구_std', '동_encoded', '동_std', '계약년']\n",
      "범주형 변수: ['아파트명', '도로명', '구', '동']\n"
     ]
    }
   ],
   "source": [
    "# 먼저, 연속형 변수와 범주형 변수를 위 info에 따라 분리해주겠습니다.\n",
    "continuous_columns = []\n",
    "categorical_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        continuous_columns.append(column)\n",
    "    else:\n",
    "        categorical_columns.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns)\n",
    "print(\"범주형 변수:\", categorical_columns)\n",
    "\n",
    "# 범주형 변수에 대한 보간\n",
    "df[categorical_columns] = df[categorical_columns].fillna('NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>have_null</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_ratio</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아파트명</td>\n",
       "      <td>object</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전용면적(㎡)</td>\n",
       "      <td>float64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>층</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>건축년도</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>도로명</td>\n",
       "      <td>object</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>target</td>\n",
       "      <td>float64</td>\n",
       "      <td>True</td>\n",
       "      <td>9272.0</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>14530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is_test</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is_public</td>\n",
       "      <td>bool</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>구</td>\n",
       "      <td>object</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>동</td>\n",
       "      <td>object</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>구_encoded</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>구_std</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>동_encoded</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>동_std</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>계약년</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_name data_type have_null  null_count  null_ratio  nunique\n",
       "0        아파트명    object     False         0.0    0.000000   6550.0\n",
       "1     전용면적(㎡)   float64     False         0.0    0.000000  14670.0\n",
       "2           층     int64     False         0.0    0.000000     73.0\n",
       "3        건축년도     int64     False         0.0    0.000000     60.0\n",
       "4         도로명    object     False         0.0    0.000000   9245.0\n",
       "5      target   float64      True      9272.0    0.008219  14530.0\n",
       "6     is_test     int64     False         0.0    0.000000      2.0\n",
       "7   is_public      bool     False         0.0    0.000000      2.0\n",
       "8           구    object     False         0.0    0.000000     25.0\n",
       "9           동    object     False         0.0    0.000000    337.0\n",
       "10  구_encoded     int64     False         0.0    0.000000     25.0\n",
       "11      구_std     int64     False         0.0    0.000000     25.0\n",
       "12  동_encoded     int64     False         0.0    0.000000    337.0\n",
       "13      동_std     int64     False         0.0    0.000000    337.0\n",
       "14        계약년     int64     False         0.0    0.000000     17.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "info_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1118822, 14) (9272, 14)\n"
     ]
    }
   ],
   "source": [
    "df_train = df.loc[df['is_test']==0, :]\n",
    "df_test = df.loc[df['is_test']==1, :]\n",
    "\n",
    "df_train.drop(['is_test'], axis=1, inplace=True)\n",
    "df_test.drop(['is_test'], axis=1, inplace=True)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_test의 target은 일단 0으로 임의로 채워주도록 하겠습니다.\n",
    "df_test['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연속형 변수: ['전용면적(㎡)', '층', '건축년도', 'target', 'is_public', '구_encoded', '구_std', '동_encoded', '동_std', '계약년']\n",
      "범주형 변수: ['아파트명', '도로명', '구', '동']\n"
     ]
    }
   ],
   "source": [
    "# 변수 삭제 및 파생변수 제작으로 추가된 변수들이 존재하기에, 다시한번 연속형과 범주형 칼럼을 분리해주겠습니다.\n",
    "continuous_columns_v2 = []\n",
    "categorical_columns_v2 = []\n",
    "\n",
    "for column in df_train.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df_train[column]):\n",
    "        continuous_columns_v2.append(column)\n",
    "    else:\n",
    "        categorical_columns_v2.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns_v2)\n",
    "print(\"범주형 변수:\", categorical_columns_v2)\n",
    "\n",
    "# 아래에서 범주형 변수들을 대상으로 레이블인코딩을 진행해 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# 각 변수에 대한 LabelEncoder를 저장할 딕셔너리\n",
    "label_encoders = {}\n",
    "\n",
    "# Implement Label Encoding\n",
    "for col in tqdm( categorical_columns_v2 ):\n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    # Label-Encoding을 fit\n",
    "    lbl.fit( df_train[col].astype(str) )\n",
    "    df_train[col] = lbl.transform(df_train[col].astype(str))\n",
    "    label_encoders[col] = lbl           # 나중에 후처리를 위해 레이블인코더를 저장해주겠습니다.\n",
    "\n",
    "    # Test 데이터에만 존재하는 새로 출현한 데이터를 신규 클래스로 추가해줍니다.\n",
    "    for label in np.unique(df_test[col]):\n",
    "      if label not in lbl.classes_: # unseen label 데이터인 경우\n",
    "        lbl.classes_ = np.append(lbl.classes_, label) # 미처리 시 ValueError발생하니 주의하세요!\n",
    "\n",
    "    df_test[col] = lbl.transform(df_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_feature_name(feature_name):\n",
    "  \"\"\"특수 문자를 제거하고 소문자로 변환합니다.\"\"\"\n",
    "  feature_name = feature_name.replace(\"-\", \"_\")\n",
    "  feature_name = feature_name.replace(\",\", \"_\")\n",
    "  feature_name = feature_name.replace(\".\", \"_\")\n",
    "  feature_name = feature_name.replace(\"(\", \"_\")\n",
    "  feature_name = feature_name.replace(\")\", \"_\")\n",
    "  feature_name = feature_name.lower()\n",
    "  return feature_name\n",
    "\n",
    "def apply_preprocessed_feature_names(df_train):\n",
    "  \"\"\"데이터 프레임의 feature 이름을 수정합니다.\"\"\"\n",
    "  df_train.columns = [preprocess_feature_name(feature) for feature in df_train.columns]\n",
    "  return df_train\n",
    "\n",
    "# 데이터 프레임에 적용\n",
    "df_train = apply_preprocessed_feature_names(df_train.copy())\n",
    "df_test = apply_preprocessed_feature_names(df_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045943 72879\n"
     ]
    }
   ],
   "source": [
    "df_train_before2021 = df_train[df_train['계약년'] <= 2020].reset_index()\n",
    "df_train_after2021 = df_train[df_train['계약년'] > 2020].reset_index()\n",
    "\n",
    "print(len(df_train_before2021), len(df_train_after2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_before2021['target']\n",
    "X = df_train_before2021.drop(['target', 'index'], axis=1)\n",
    "X_test = df_test.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1651\n",
      "[LightGBM] [Info] Number of data points in the train set: 836754, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 54855.987417\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 9961.39\ttraining's l2: 9.92293e+07\tvalid_1's rmse: 10219.4\tvalid_1's l2: 1.04437e+08\n",
      "[100]\ttraining's rmse: 8380.95\ttraining's l2: 7.02404e+07\tvalid_1's rmse: 8669.63\tvalid_1's l2: 7.51624e+07\n",
      "[150]\ttraining's rmse: 7777.61\ttraining's l2: 6.04912e+07\tvalid_1's rmse: 8105.08\tvalid_1's l2: 6.56924e+07\n",
      "[200]\ttraining's rmse: 7389.48\ttraining's l2: 5.46045e+07\tvalid_1's rmse: 7749.55\tvalid_1's l2: 6.00555e+07\n",
      "[250]\ttraining's rmse: 7103.65\ttraining's l2: 5.04618e+07\tvalid_1's rmse: 7488.97\tvalid_1's l2: 5.60847e+07\n",
      "[300]\ttraining's rmse: 6871.86\ttraining's l2: 4.72224e+07\tvalid_1's rmse: 7285.63\tvalid_1's l2: 5.30804e+07\n",
      "[350]\ttraining's rmse: 6685.86\ttraining's l2: 4.47008e+07\tvalid_1's rmse: 7127.09\tvalid_1's l2: 5.07954e+07\n",
      "[400]\ttraining's rmse: 6553.06\ttraining's l2: 4.29426e+07\tvalid_1's rmse: 7016.59\tvalid_1's l2: 4.92325e+07\n",
      "[450]\ttraining's rmse: 6428.22\ttraining's l2: 4.13221e+07\tvalid_1's rmse: 6915.43\tvalid_1's l2: 4.78232e+07\n",
      "[500]\ttraining's rmse: 6333.79\ttraining's l2: 4.01169e+07\tvalid_1's rmse: 6842.24\tvalid_1's l2: 4.68162e+07\n",
      "[550]\ttraining's rmse: 6238\ttraining's l2: 3.89126e+07\tvalid_1's rmse: 6772.5\tvalid_1's l2: 4.58667e+07\n",
      "[600]\ttraining's rmse: 6145.56\ttraining's l2: 3.77679e+07\tvalid_1's rmse: 6701.23\tvalid_1's l2: 4.49065e+07\n",
      "[650]\ttraining's rmse: 6076.49\ttraining's l2: 3.69237e+07\tvalid_1's rmse: 6651.55\tvalid_1's l2: 4.42431e+07\n",
      "[700]\ttraining's rmse: 6010.9\ttraining's l2: 3.61309e+07\tvalid_1's rmse: 6605.9\tvalid_1's l2: 4.36379e+07\n",
      "[750]\ttraining's rmse: 5954.01\ttraining's l2: 3.54502e+07\tvalid_1's rmse: 6564.75\tvalid_1's l2: 4.30959e+07\n",
      "[800]\ttraining's rmse: 5901.3\ttraining's l2: 3.48253e+07\tvalid_1's rmse: 6528.06\tvalid_1's l2: 4.26156e+07\n",
      "[850]\ttraining's rmse: 5852.18\ttraining's l2: 3.4248e+07\tvalid_1's rmse: 6494.01\tvalid_1's l2: 4.21721e+07\n",
      "[900]\ttraining's rmse: 5805.89\ttraining's l2: 3.37084e+07\tvalid_1's rmse: 6465.02\tvalid_1's l2: 4.17965e+07\n",
      "[950]\ttraining's rmse: 5757.44\ttraining's l2: 3.31481e+07\tvalid_1's rmse: 6436.78\tvalid_1's l2: 4.14321e+07\n",
      "[1000]\ttraining's rmse: 5715.14\ttraining's l2: 3.26628e+07\tvalid_1's rmse: 6410.28\tvalid_1's l2: 4.10917e+07\n",
      "[1050]\ttraining's rmse: 5678.26\ttraining's l2: 3.22426e+07\tvalid_1's rmse: 6387.89\tvalid_1's l2: 4.08052e+07\n",
      "[1100]\ttraining's rmse: 5642.56\ttraining's l2: 3.18385e+07\tvalid_1's rmse: 6367.87\tvalid_1's l2: 4.05498e+07\n",
      "[1150]\ttraining's rmse: 5608.94\ttraining's l2: 3.14602e+07\tvalid_1's rmse: 6347.83\tvalid_1's l2: 4.0295e+07\n",
      "[1200]\ttraining's rmse: 5574.95\ttraining's l2: 3.10801e+07\tvalid_1's rmse: 6326.55\tvalid_1's l2: 4.00252e+07\n",
      "[1250]\ttraining's rmse: 5543.63\ttraining's l2: 3.07318e+07\tvalid_1's rmse: 6309.13\tvalid_1's l2: 3.98051e+07\n",
      "[1300]\ttraining's rmse: 5513.97\ttraining's l2: 3.04038e+07\tvalid_1's rmse: 6291.13\tvalid_1's l2: 3.95784e+07\n",
      "[1350]\ttraining's rmse: 5488.23\ttraining's l2: 3.01206e+07\tvalid_1's rmse: 6278.27\tvalid_1's l2: 3.94167e+07\n",
      "[1400]\ttraining's rmse: 5462.72\ttraining's l2: 2.98413e+07\tvalid_1's rmse: 6265.07\tvalid_1's l2: 3.92511e+07\n",
      "[1450]\ttraining's rmse: 5434.26\ttraining's l2: 2.95312e+07\tvalid_1's rmse: 6251.26\tvalid_1's l2: 3.90782e+07\n",
      "[1500]\ttraining's rmse: 5408.45\ttraining's l2: 2.92513e+07\tvalid_1's rmse: 6239.85\tvalid_1's l2: 3.89357e+07\n",
      "[1550]\ttraining's rmse: 5388.04\ttraining's l2: 2.90309e+07\tvalid_1's rmse: 6229.37\tvalid_1's l2: 3.8805e+07\n",
      "[1600]\ttraining's rmse: 5367.27\ttraining's l2: 2.88076e+07\tvalid_1's rmse: 6219.02\tvalid_1's l2: 3.86762e+07\n",
      "[1650]\ttraining's rmse: 5346.02\ttraining's l2: 2.858e+07\tvalid_1's rmse: 6209.88\tvalid_1's l2: 3.85626e+07\n",
      "[1700]\ttraining's rmse: 5326.27\ttraining's l2: 2.83692e+07\tvalid_1's rmse: 6201.97\tvalid_1's l2: 3.84644e+07\n",
      "[1750]\ttraining's rmse: 5306.99\ttraining's l2: 2.81642e+07\tvalid_1's rmse: 6193.16\tvalid_1's l2: 3.83553e+07\n",
      "[1800]\ttraining's rmse: 5281.42\ttraining's l2: 2.78934e+07\tvalid_1's rmse: 6185.68\tvalid_1's l2: 3.82627e+07\n",
      "[1850]\ttraining's rmse: 5259.87\ttraining's l2: 2.76662e+07\tvalid_1's rmse: 6178.87\tvalid_1's l2: 3.81784e+07\n",
      "[1900]\ttraining's rmse: 5239.09\ttraining's l2: 2.74481e+07\tvalid_1's rmse: 6170.15\tvalid_1's l2: 3.80708e+07\n",
      "[1950]\ttraining's rmse: 5220.54\ttraining's l2: 2.7254e+07\tvalid_1's rmse: 6162.49\tvalid_1's l2: 3.79763e+07\n",
      "[2000]\ttraining's rmse: 5205.24\ttraining's l2: 2.70946e+07\tvalid_1's rmse: 6156.85\tvalid_1's l2: 3.79068e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 5205.24\ttraining's l2: 2.70946e+07\tvalid_1's rmse: 6156.85\tvalid_1's l2: 3.79068e+07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1649\n",
      "[LightGBM] [Info] Number of data points in the train set: 836754, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 54822.918111\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 9952.92\ttraining's l2: 9.90606e+07\tvalid_1's rmse: 10136.3\tvalid_1's l2: 1.02744e+08\n",
      "[100]\ttraining's rmse: 8395.23\ttraining's l2: 7.04799e+07\tvalid_1's rmse: 8616.31\tvalid_1's l2: 7.42408e+07\n",
      "[150]\ttraining's rmse: 7785.17\ttraining's l2: 6.06089e+07\tvalid_1's rmse: 8031.85\tvalid_1's l2: 6.45107e+07\n",
      "[200]\ttraining's rmse: 7407.48\ttraining's l2: 5.48708e+07\tvalid_1's rmse: 7691.45\tvalid_1's l2: 5.91584e+07\n",
      "[250]\ttraining's rmse: 7114.88\ttraining's l2: 5.06216e+07\tvalid_1's rmse: 7433.41\tvalid_1's l2: 5.52556e+07\n",
      "[300]\ttraining's rmse: 6900.23\ttraining's l2: 4.76132e+07\tvalid_1's rmse: 7249.88\tvalid_1's l2: 5.25607e+07\n",
      "[350]\ttraining's rmse: 6719.29\ttraining's l2: 4.51488e+07\tvalid_1's rmse: 7100.2\tvalid_1's l2: 5.04129e+07\n",
      "[400]\ttraining's rmse: 6584.13\ttraining's l2: 4.33508e+07\tvalid_1's rmse: 6995.42\tvalid_1's l2: 4.8936e+07\n",
      "[450]\ttraining's rmse: 6466.29\ttraining's l2: 4.18128e+07\tvalid_1's rmse: 6903.71\tvalid_1's l2: 4.76612e+07\n",
      "[500]\ttraining's rmse: 6365.19\ttraining's l2: 4.05156e+07\tvalid_1's rmse: 6830.05\tvalid_1's l2: 4.66496e+07\n",
      "[550]\ttraining's rmse: 6274.91\ttraining's l2: 3.93745e+07\tvalid_1's rmse: 6763.4\tvalid_1's l2: 4.57436e+07\n",
      "[600]\ttraining's rmse: 6197.15\ttraining's l2: 3.84047e+07\tvalid_1's rmse: 6705.13\tvalid_1's l2: 4.49587e+07\n",
      "[650]\ttraining's rmse: 6124.09\ttraining's l2: 3.75044e+07\tvalid_1's rmse: 6648.51\tvalid_1's l2: 4.42027e+07\n",
      "[700]\ttraining's rmse: 6050.59\ttraining's l2: 3.66096e+07\tvalid_1's rmse: 6597.47\tvalid_1's l2: 4.35266e+07\n",
      "[750]\ttraining's rmse: 5986.03\ttraining's l2: 3.58326e+07\tvalid_1's rmse: 6551.91\tvalid_1's l2: 4.29275e+07\n",
      "[800]\ttraining's rmse: 5928.06\ttraining's l2: 3.51419e+07\tvalid_1's rmse: 6509.67\tvalid_1's l2: 4.23758e+07\n",
      "[850]\ttraining's rmse: 5875.54\ttraining's l2: 3.4522e+07\tvalid_1's rmse: 6476.18\tvalid_1's l2: 4.19409e+07\n",
      "[900]\ttraining's rmse: 5825.65\ttraining's l2: 3.39382e+07\tvalid_1's rmse: 6444.48\tvalid_1's l2: 4.15313e+07\n",
      "[950]\ttraining's rmse: 5779.39\ttraining's l2: 3.34014e+07\tvalid_1's rmse: 6418.35\tvalid_1's l2: 4.11953e+07\n",
      "[1000]\ttraining's rmse: 5734.7\ttraining's l2: 3.28868e+07\tvalid_1's rmse: 6390.41\tvalid_1's l2: 4.08373e+07\n",
      "[1050]\ttraining's rmse: 5700.35\ttraining's l2: 3.2494e+07\tvalid_1's rmse: 6368.25\tvalid_1's l2: 4.05546e+07\n",
      "[1100]\ttraining's rmse: 5660.88\ttraining's l2: 3.20455e+07\tvalid_1's rmse: 6345.62\tvalid_1's l2: 4.02669e+07\n",
      "[1150]\ttraining's rmse: 5620.68\ttraining's l2: 3.1592e+07\tvalid_1's rmse: 6320.19\tvalid_1's l2: 3.99447e+07\n",
      "[1200]\ttraining's rmse: 5585.57\ttraining's l2: 3.11986e+07\tvalid_1's rmse: 6303.45\tvalid_1's l2: 3.97335e+07\n",
      "[1250]\ttraining's rmse: 5550.04\ttraining's l2: 3.0803e+07\tvalid_1's rmse: 6281.45\tvalid_1's l2: 3.94566e+07\n",
      "[1300]\ttraining's rmse: 5517.82\ttraining's l2: 3.04463e+07\tvalid_1's rmse: 6264.1\tvalid_1's l2: 3.9239e+07\n",
      "[1350]\ttraining's rmse: 5487.57\ttraining's l2: 3.01134e+07\tvalid_1's rmse: 6247.82\tvalid_1's l2: 3.90353e+07\n",
      "[1400]\ttraining's rmse: 5462.43\ttraining's l2: 2.98381e+07\tvalid_1's rmse: 6235.68\tvalid_1's l2: 3.88837e+07\n",
      "[1450]\ttraining's rmse: 5436.09\ttraining's l2: 2.9551e+07\tvalid_1's rmse: 6224.41\tvalid_1's l2: 3.87432e+07\n",
      "[1500]\ttraining's rmse: 5412.04\ttraining's l2: 2.92902e+07\tvalid_1's rmse: 6213.77\tvalid_1's l2: 3.86109e+07\n",
      "[1550]\ttraining's rmse: 5388.03\ttraining's l2: 2.90308e+07\tvalid_1's rmse: 6202.33\tvalid_1's l2: 3.84689e+07\n",
      "[1600]\ttraining's rmse: 5365.45\ttraining's l2: 2.87881e+07\tvalid_1's rmse: 6189.79\tvalid_1's l2: 3.83135e+07\n",
      "[1650]\ttraining's rmse: 5343.01\ttraining's l2: 2.85477e+07\tvalid_1's rmse: 6180.52\tvalid_1's l2: 3.81988e+07\n",
      "[1700]\ttraining's rmse: 5320.22\ttraining's l2: 2.83047e+07\tvalid_1's rmse: 6170.66\tvalid_1's l2: 3.8077e+07\n",
      "[1750]\ttraining's rmse: 5299.76\ttraining's l2: 2.80875e+07\tvalid_1's rmse: 6162.59\tvalid_1's l2: 3.79775e+07\n",
      "[1800]\ttraining's rmse: 5279.29\ttraining's l2: 2.78709e+07\tvalid_1's rmse: 6155.92\tvalid_1's l2: 3.78954e+07\n",
      "[1850]\ttraining's rmse: 5259.96\ttraining's l2: 2.76671e+07\tvalid_1's rmse: 6146.89\tvalid_1's l2: 3.77842e+07\n",
      "[1900]\ttraining's rmse: 5240.9\ttraining's l2: 2.7467e+07\tvalid_1's rmse: 6139.09\tvalid_1's l2: 3.76884e+07\n",
      "[1950]\ttraining's rmse: 5223.31\ttraining's l2: 2.72829e+07\tvalid_1's rmse: 6131.68\tvalid_1's l2: 3.75975e+07\n",
      "[2000]\ttraining's rmse: 5206.43\ttraining's l2: 2.71069e+07\tvalid_1's rmse: 6125.79\tvalid_1's l2: 3.75253e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 5206.43\ttraining's l2: 2.71069e+07\tvalid_1's rmse: 6125.79\tvalid_1's l2: 3.75253e+07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1650\n",
      "[LightGBM] [Info] Number of data points in the train set: 836754, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 54862.047731\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 9977.19\ttraining's l2: 9.95443e+07\tvalid_1's rmse: 10148.2\tvalid_1's l2: 1.02987e+08\n",
      "[100]\ttraining's rmse: 8382.85\ttraining's l2: 7.02722e+07\tvalid_1's rmse: 8616.93\tvalid_1's l2: 7.42515e+07\n",
      "[150]\ttraining's rmse: 7768.24\ttraining's l2: 6.03456e+07\tvalid_1's rmse: 8050.8\tvalid_1's l2: 6.48154e+07\n",
      "[200]\ttraining's rmse: 7373.54\ttraining's l2: 5.43691e+07\tvalid_1's rmse: 7701.66\tvalid_1's l2: 5.93156e+07\n",
      "[250]\ttraining's rmse: 7082.83\ttraining's l2: 5.01665e+07\tvalid_1's rmse: 7446.41\tvalid_1's l2: 5.5449e+07\n",
      "[300]\ttraining's rmse: 6873.92\ttraining's l2: 4.72508e+07\tvalid_1's rmse: 7272.06\tvalid_1's l2: 5.28828e+07\n",
      "[350]\ttraining's rmse: 6706.04\ttraining's l2: 4.4971e+07\tvalid_1's rmse: 7133.98\tvalid_1's l2: 5.08937e+07\n",
      "[400]\ttraining's rmse: 6557.87\ttraining's l2: 4.30056e+07\tvalid_1's rmse: 7011.26\tvalid_1's l2: 4.91577e+07\n",
      "[450]\ttraining's rmse: 6435.18\ttraining's l2: 4.14116e+07\tvalid_1's rmse: 6913.42\tvalid_1's l2: 4.77954e+07\n",
      "[500]\ttraining's rmse: 6331.21\ttraining's l2: 4.00843e+07\tvalid_1's rmse: 6834.16\tvalid_1's l2: 4.67057e+07\n",
      "[550]\ttraining's rmse: 6234.99\ttraining's l2: 3.88751e+07\tvalid_1's rmse: 6759.07\tvalid_1's l2: 4.56851e+07\n",
      "[600]\ttraining's rmse: 6154.91\ttraining's l2: 3.78829e+07\tvalid_1's rmse: 6701.59\tvalid_1's l2: 4.49113e+07\n",
      "[650]\ttraining's rmse: 6078.42\ttraining's l2: 3.69472e+07\tvalid_1's rmse: 6646.93\tvalid_1's l2: 4.41816e+07\n",
      "[700]\ttraining's rmse: 6010.21\ttraining's l2: 3.61226e+07\tvalid_1's rmse: 6600.28\tvalid_1's l2: 4.35638e+07\n",
      "[750]\ttraining's rmse: 5944\ttraining's l2: 3.53311e+07\tvalid_1's rmse: 6553.6\tvalid_1's l2: 4.29496e+07\n",
      "[800]\ttraining's rmse: 5887.48\ttraining's l2: 3.46624e+07\tvalid_1's rmse: 6515.41\tvalid_1's l2: 4.24506e+07\n",
      "[850]\ttraining's rmse: 5840.63\ttraining's l2: 3.41129e+07\tvalid_1's rmse: 6485.64\tvalid_1's l2: 4.20636e+07\n",
      "[900]\ttraining's rmse: 5794.12\ttraining's l2: 3.35718e+07\tvalid_1's rmse: 6456.95\tvalid_1's l2: 4.16922e+07\n",
      "[950]\ttraining's rmse: 5745\ttraining's l2: 3.3005e+07\tvalid_1's rmse: 6429.74\tvalid_1's l2: 4.13416e+07\n",
      "[1000]\ttraining's rmse: 5706.35\ttraining's l2: 3.25624e+07\tvalid_1's rmse: 6408.83\tvalid_1's l2: 4.10731e+07\n",
      "[1050]\ttraining's rmse: 5663.57\ttraining's l2: 3.2076e+07\tvalid_1's rmse: 6385.07\tvalid_1's l2: 4.07691e+07\n",
      "[1100]\ttraining's rmse: 5633.55\ttraining's l2: 3.17369e+07\tvalid_1's rmse: 6364.67\tvalid_1's l2: 4.05091e+07\n",
      "[1150]\ttraining's rmse: 5603.26\ttraining's l2: 3.13965e+07\tvalid_1's rmse: 6346.47\tvalid_1's l2: 4.02777e+07\n",
      "[1200]\ttraining's rmse: 5568.26\ttraining's l2: 3.10055e+07\tvalid_1's rmse: 6325.78\tvalid_1's l2: 4.00154e+07\n",
      "[1250]\ttraining's rmse: 5534.04\ttraining's l2: 3.06256e+07\tvalid_1's rmse: 6306.73\tvalid_1's l2: 3.97748e+07\n",
      "[1300]\ttraining's rmse: 5504.03\ttraining's l2: 3.02943e+07\tvalid_1's rmse: 6290.75\tvalid_1's l2: 3.95735e+07\n",
      "[1350]\ttraining's rmse: 5476.75\ttraining's l2: 2.99948e+07\tvalid_1's rmse: 6275.97\tvalid_1's l2: 3.93878e+07\n",
      "[1400]\ttraining's rmse: 5446.78\ttraining's l2: 2.96674e+07\tvalid_1's rmse: 6264.38\tvalid_1's l2: 3.92425e+07\n",
      "[1450]\ttraining's rmse: 5420.75\ttraining's l2: 2.93845e+07\tvalid_1's rmse: 6250.78\tvalid_1's l2: 3.90722e+07\n",
      "[1500]\ttraining's rmse: 5398.94\ttraining's l2: 2.91486e+07\tvalid_1's rmse: 6239.55\tvalid_1's l2: 3.8932e+07\n",
      "[1550]\ttraining's rmse: 5374.6\ttraining's l2: 2.88864e+07\tvalid_1's rmse: 6228.06\tvalid_1's l2: 3.87888e+07\n",
      "[1600]\ttraining's rmse: 5354.2\ttraining's l2: 2.86675e+07\tvalid_1's rmse: 6217.13\tvalid_1's l2: 3.86527e+07\n",
      "[1650]\ttraining's rmse: 5334.8\ttraining's l2: 2.84601e+07\tvalid_1's rmse: 6209.11\tvalid_1's l2: 3.8553e+07\n",
      "[1700]\ttraining's rmse: 5316.98\ttraining's l2: 2.82702e+07\tvalid_1's rmse: 6201.55\tvalid_1's l2: 3.84592e+07\n",
      "[1750]\ttraining's rmse: 5296.68\ttraining's l2: 2.80548e+07\tvalid_1's rmse: 6194.26\tvalid_1's l2: 3.83688e+07\n",
      "[1800]\ttraining's rmse: 5276.78\ttraining's l2: 2.78444e+07\tvalid_1's rmse: 6187.1\tvalid_1's l2: 3.82802e+07\n",
      "[1850]\ttraining's rmse: 5258.73\ttraining's l2: 2.76542e+07\tvalid_1's rmse: 6179.31\tvalid_1's l2: 3.81838e+07\n",
      "[1900]\ttraining's rmse: 5238.42\ttraining's l2: 2.7441e+07\tvalid_1's rmse: 6172.35\tvalid_1's l2: 3.80978e+07\n",
      "[1950]\ttraining's rmse: 5218.8\ttraining's l2: 2.72359e+07\tvalid_1's rmse: 6164.81\tvalid_1's l2: 3.80049e+07\n",
      "[2000]\ttraining's rmse: 5199.17\ttraining's l2: 2.70314e+07\tvalid_1's rmse: 6159.63\tvalid_1's l2: 3.7941e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 5199.17\ttraining's l2: 2.70314e+07\tvalid_1's rmse: 6159.63\tvalid_1's l2: 3.7941e+07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1652\n",
      "[LightGBM] [Info] Number of data points in the train set: 836754, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 54886.011441\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 9952.42\ttraining's l2: 9.90507e+07\tvalid_1's rmse: 10035.8\tvalid_1's l2: 1.00717e+08\n",
      "[100]\ttraining's rmse: 8392.54\ttraining's l2: 7.04347e+07\tvalid_1's rmse: 8541.23\tvalid_1's l2: 7.29526e+07\n",
      "[150]\ttraining's rmse: 7782.72\ttraining's l2: 6.05708e+07\tvalid_1's rmse: 7971.35\tvalid_1's l2: 6.35424e+07\n",
      "[200]\ttraining's rmse: 7412.16\ttraining's l2: 5.49401e+07\tvalid_1's rmse: 7646.29\tvalid_1's l2: 5.84657e+07\n",
      "[250]\ttraining's rmse: 7147.71\ttraining's l2: 5.10898e+07\tvalid_1's rmse: 7416.65\tvalid_1's l2: 5.50068e+07\n",
      "[300]\ttraining's rmse: 6911.06\ttraining's l2: 4.77627e+07\tvalid_1's rmse: 7203.74\tvalid_1's l2: 5.18939e+07\n",
      "[350]\ttraining's rmse: 6735.49\ttraining's l2: 4.53668e+07\tvalid_1's rmse: 7052.54\tvalid_1's l2: 4.97383e+07\n",
      "[400]\ttraining's rmse: 6584.38\ttraining's l2: 4.33541e+07\tvalid_1's rmse: 6925.63\tvalid_1's l2: 4.79644e+07\n",
      "[450]\ttraining's rmse: 6459.22\ttraining's l2: 4.17215e+07\tvalid_1's rmse: 6824.78\tvalid_1's l2: 4.65776e+07\n",
      "[500]\ttraining's rmse: 6363.18\ttraining's l2: 4.04901e+07\tvalid_1's rmse: 6749.37\tvalid_1's l2: 4.5554e+07\n",
      "[550]\ttraining's rmse: 6267.09\ttraining's l2: 3.92764e+07\tvalid_1's rmse: 6676.24\tvalid_1's l2: 4.45721e+07\n",
      "[600]\ttraining's rmse: 6184.7\ttraining's l2: 3.82505e+07\tvalid_1's rmse: 6611.62\tvalid_1's l2: 4.37135e+07\n",
      "[650]\ttraining's rmse: 6108.8\ttraining's l2: 3.73175e+07\tvalid_1's rmse: 6556.24\tvalid_1's l2: 4.29843e+07\n",
      "[700]\ttraining's rmse: 6047.77\ttraining's l2: 3.65755e+07\tvalid_1's rmse: 6514.22\tvalid_1's l2: 4.2435e+07\n",
      "[750]\ttraining's rmse: 5986.47\ttraining's l2: 3.58378e+07\tvalid_1's rmse: 6472.65\tvalid_1's l2: 4.18952e+07\n",
      "[800]\ttraining's rmse: 5930.03\ttraining's l2: 3.51653e+07\tvalid_1's rmse: 6437.26\tvalid_1's l2: 4.14384e+07\n",
      "[850]\ttraining's rmse: 5872.99\ttraining's l2: 3.44921e+07\tvalid_1's rmse: 6399.38\tvalid_1's l2: 4.0952e+07\n",
      "[900]\ttraining's rmse: 5828.68\ttraining's l2: 3.39735e+07\tvalid_1's rmse: 6370.17\tvalid_1's l2: 4.05791e+07\n",
      "[950]\ttraining's rmse: 5787.06\ttraining's l2: 3.34901e+07\tvalid_1's rmse: 6343.52\tvalid_1's l2: 4.02402e+07\n",
      "[1000]\ttraining's rmse: 5741.36\ttraining's l2: 3.29632e+07\tvalid_1's rmse: 6316\tvalid_1's l2: 3.98918e+07\n",
      "[1050]\ttraining's rmse: 5702.42\ttraining's l2: 3.25176e+07\tvalid_1's rmse: 6292.33\tvalid_1's l2: 3.95934e+07\n",
      "[1100]\ttraining's rmse: 5660.21\ttraining's l2: 3.2038e+07\tvalid_1's rmse: 6268.05\tvalid_1's l2: 3.92884e+07\n",
      "[1150]\ttraining's rmse: 5623.1\ttraining's l2: 3.16192e+07\tvalid_1's rmse: 6247.64\tvalid_1's l2: 3.9033e+07\n",
      "[1200]\ttraining's rmse: 5590.66\ttraining's l2: 3.12555e+07\tvalid_1's rmse: 6230.42\tvalid_1's l2: 3.88181e+07\n",
      "[1250]\ttraining's rmse: 5558.33\ttraining's l2: 3.08951e+07\tvalid_1's rmse: 6213.97\tvalid_1's l2: 3.86135e+07\n",
      "[1300]\ttraining's rmse: 5526.92\ttraining's l2: 3.05469e+07\tvalid_1's rmse: 6198.53\tvalid_1's l2: 3.84218e+07\n",
      "[1350]\ttraining's rmse: 5498.83\ttraining's l2: 3.02371e+07\tvalid_1's rmse: 6182.83\tvalid_1's l2: 3.82274e+07\n",
      "[1400]\ttraining's rmse: 5471.55\ttraining's l2: 2.99379e+07\tvalid_1's rmse: 6171.87\tvalid_1's l2: 3.80919e+07\n",
      "[1450]\ttraining's rmse: 5444.21\ttraining's l2: 2.96395e+07\tvalid_1's rmse: 6161.45\tvalid_1's l2: 3.79634e+07\n",
      "[1500]\ttraining's rmse: 5418.22\ttraining's l2: 2.93571e+07\tvalid_1's rmse: 6147.6\tvalid_1's l2: 3.7793e+07\n",
      "[1550]\ttraining's rmse: 5393.63\ttraining's l2: 2.90912e+07\tvalid_1's rmse: 6135.35\tvalid_1's l2: 3.76425e+07\n",
      "[1600]\ttraining's rmse: 5370.37\ttraining's l2: 2.88409e+07\tvalid_1's rmse: 6124.78\tvalid_1's l2: 3.75129e+07\n",
      "[1650]\ttraining's rmse: 5348.57\ttraining's l2: 2.86072e+07\tvalid_1's rmse: 6116.15\tvalid_1's l2: 3.74073e+07\n",
      "[1700]\ttraining's rmse: 5328.11\ttraining's l2: 2.83887e+07\tvalid_1's rmse: 6108.02\tvalid_1's l2: 3.73079e+07\n",
      "[1750]\ttraining's rmse: 5307.97\ttraining's l2: 2.81745e+07\tvalid_1's rmse: 6103.26\tvalid_1's l2: 3.72498e+07\n",
      "[1800]\ttraining's rmse: 5287.19\ttraining's l2: 2.79544e+07\tvalid_1's rmse: 6096.28\tvalid_1's l2: 3.71646e+07\n",
      "[1850]\ttraining's rmse: 5265.71\ttraining's l2: 2.77277e+07\tvalid_1's rmse: 6088.16\tvalid_1's l2: 3.70657e+07\n",
      "[1900]\ttraining's rmse: 5245.66\ttraining's l2: 2.7517e+07\tvalid_1's rmse: 6081.79\tvalid_1's l2: 3.69882e+07\n",
      "[1950]\ttraining's rmse: 5225.94\ttraining's l2: 2.73104e+07\tvalid_1's rmse: 6076.46\tvalid_1's l2: 3.69234e+07\n",
      "[2000]\ttraining's rmse: 5208.13\ttraining's l2: 2.71246e+07\tvalid_1's rmse: 6069.7\tvalid_1's l2: 3.68412e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 5208.13\ttraining's l2: 2.71246e+07\tvalid_1's rmse: 6069.7\tvalid_1's l2: 3.68412e+07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1649\n",
      "[LightGBM] [Info] Number of data points in the train set: 836754, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 54861.342509\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 9980.25\ttraining's l2: 9.96053e+07\tvalid_1's rmse: 10063.1\tvalid_1's l2: 1.01267e+08\n",
      "[100]\ttraining's rmse: 8413.44\ttraining's l2: 7.0786e+07\tvalid_1's rmse: 8573.55\tvalid_1's l2: 7.35058e+07\n",
      "[150]\ttraining's rmse: 7791.22\ttraining's l2: 6.0703e+07\tvalid_1's rmse: 8001.64\tvalid_1's l2: 6.40263e+07\n",
      "[200]\ttraining's rmse: 7408.61\ttraining's l2: 5.48874e+07\tvalid_1's rmse: 7658.72\tvalid_1's l2: 5.8656e+07\n",
      "[250]\ttraining's rmse: 7139.08\ttraining's l2: 5.09665e+07\tvalid_1's rmse: 7425.61\tvalid_1's l2: 5.51397e+07\n",
      "[300]\ttraining's rmse: 6931.66\ttraining's l2: 4.80479e+07\tvalid_1's rmse: 7245.27\tvalid_1's l2: 5.24939e+07\n",
      "[350]\ttraining's rmse: 6756.16\ttraining's l2: 4.56457e+07\tvalid_1's rmse: 7105.37\tvalid_1's l2: 5.04863e+07\n",
      "[400]\ttraining's rmse: 6602.14\ttraining's l2: 4.35883e+07\tvalid_1's rmse: 6974.89\tvalid_1's l2: 4.8649e+07\n",
      "[450]\ttraining's rmse: 6472\ttraining's l2: 4.18868e+07\tvalid_1's rmse: 6877.57\tvalid_1's l2: 4.7301e+07\n",
      "[500]\ttraining's rmse: 6364.78\ttraining's l2: 4.05104e+07\tvalid_1's rmse: 6796.71\tvalid_1's l2: 4.61953e+07\n",
      "[550]\ttraining's rmse: 6263.72\ttraining's l2: 3.92342e+07\tvalid_1's rmse: 6718.14\tvalid_1's l2: 4.51334e+07\n",
      "[600]\ttraining's rmse: 6169.24\ttraining's l2: 3.80595e+07\tvalid_1's rmse: 6653.36\tvalid_1's l2: 4.42672e+07\n",
      "[650]\ttraining's rmse: 6092.05\ttraining's l2: 3.71131e+07\tvalid_1's rmse: 6600.72\tvalid_1's l2: 4.35695e+07\n",
      "[700]\ttraining's rmse: 6016.95\ttraining's l2: 3.62037e+07\tvalid_1's rmse: 6551.08\tvalid_1's l2: 4.29167e+07\n",
      "[750]\ttraining's rmse: 5961.34\ttraining's l2: 3.55376e+07\tvalid_1's rmse: 6511.31\tvalid_1's l2: 4.23972e+07\n",
      "[800]\ttraining's rmse: 5906.56\ttraining's l2: 3.48875e+07\tvalid_1's rmse: 6477.27\tvalid_1's l2: 4.1955e+07\n",
      "[850]\ttraining's rmse: 5855.26\ttraining's l2: 3.42841e+07\tvalid_1's rmse: 6446.17\tvalid_1's l2: 4.15531e+07\n",
      "[900]\ttraining's rmse: 5804.84\ttraining's l2: 3.36962e+07\tvalid_1's rmse: 6417\tvalid_1's l2: 4.11779e+07\n",
      "[950]\ttraining's rmse: 5759\ttraining's l2: 3.31661e+07\tvalid_1's rmse: 6388.7\tvalid_1's l2: 4.08155e+07\n",
      "[1000]\ttraining's rmse: 5717.95\ttraining's l2: 3.2695e+07\tvalid_1's rmse: 6365.39\tvalid_1's l2: 4.05182e+07\n",
      "[1050]\ttraining's rmse: 5680.78\ttraining's l2: 3.22713e+07\tvalid_1's rmse: 6344.28\tvalid_1's l2: 4.02499e+07\n",
      "[1100]\ttraining's rmse: 5641.93\ttraining's l2: 3.18313e+07\tvalid_1's rmse: 6324.95\tvalid_1's l2: 4.0005e+07\n",
      "[1150]\ttraining's rmse: 5607.83\ttraining's l2: 3.14478e+07\tvalid_1's rmse: 6305.69\tvalid_1's l2: 3.97618e+07\n",
      "[1200]\ttraining's rmse: 5574.61\ttraining's l2: 3.10763e+07\tvalid_1's rmse: 6285.6\tvalid_1's l2: 3.95088e+07\n",
      "[1250]\ttraining's rmse: 5544.66\ttraining's l2: 3.07433e+07\tvalid_1's rmse: 6270.45\tvalid_1's l2: 3.93186e+07\n",
      "[1300]\ttraining's rmse: 5517.07\ttraining's l2: 3.0438e+07\tvalid_1's rmse: 6254.21\tvalid_1's l2: 3.91151e+07\n",
      "[1350]\ttraining's rmse: 5484.74\ttraining's l2: 3.00823e+07\tvalid_1's rmse: 6240.63\tvalid_1's l2: 3.89455e+07\n",
      "[1400]\ttraining's rmse: 5453.27\ttraining's l2: 2.97382e+07\tvalid_1's rmse: 6227.56\tvalid_1's l2: 3.87826e+07\n",
      "[1450]\ttraining's rmse: 5429.35\ttraining's l2: 2.94778e+07\tvalid_1's rmse: 6217.14\tvalid_1's l2: 3.86529e+07\n",
      "[1500]\ttraining's rmse: 5404.74\ttraining's l2: 2.92112e+07\tvalid_1's rmse: 6206.23\tvalid_1's l2: 3.85172e+07\n",
      "[1550]\ttraining's rmse: 5381.77\ttraining's l2: 2.89635e+07\tvalid_1's rmse: 6197.68\tvalid_1's l2: 3.84113e+07\n",
      "[1600]\ttraining's rmse: 5359.29\ttraining's l2: 2.8722e+07\tvalid_1's rmse: 6186.99\tvalid_1's l2: 3.82789e+07\n",
      "[1650]\ttraining's rmse: 5338.82\ttraining's l2: 2.8503e+07\tvalid_1's rmse: 6178.55\tvalid_1's l2: 3.81745e+07\n",
      "[1700]\ttraining's rmse: 5317.35\ttraining's l2: 2.82742e+07\tvalid_1's rmse: 6168.19\tvalid_1's l2: 3.80466e+07\n",
      "[1750]\ttraining's rmse: 5292.51\ttraining's l2: 2.80106e+07\tvalid_1's rmse: 6160.29\tvalid_1's l2: 3.79492e+07\n",
      "[1800]\ttraining's rmse: 5272.99\ttraining's l2: 2.78044e+07\tvalid_1's rmse: 6151.78\tvalid_1's l2: 3.78444e+07\n",
      "[1850]\ttraining's rmse: 5256.88\ttraining's l2: 2.76348e+07\tvalid_1's rmse: 6144.7\tvalid_1's l2: 3.77573e+07\n",
      "[1900]\ttraining's rmse: 5238.21\ttraining's l2: 2.74389e+07\tvalid_1's rmse: 6136.76\tvalid_1's l2: 3.76599e+07\n",
      "[1950]\ttraining's rmse: 5220.9\ttraining's l2: 2.72578e+07\tvalid_1's rmse: 6130.37\tvalid_1's l2: 3.75814e+07\n",
      "[2000]\ttraining's rmse: 5201.18\ttraining's l2: 2.70522e+07\tvalid_1's rmse: 6125.78\tvalid_1's l2: 3.75252e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 5201.18\ttraining's l2: 2.70522e+07\tvalid_1's rmse: 6125.78\tvalid_1's l2: 3.75252e+07\n"
     ]
    }
   ],
   "source": [
    "gbm_list = []\n",
    "for random_state in [0, 1, 42, 2023, 2024]:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    gbm = lgb.LGBMRegressor(n_estimators=2000, max_depth=20, num_leaves=100,\n",
    "                        min_child_samples=60, feature_fraction=0.8,\n",
    "                        bagging_fraction=0.8)\n",
    "\n",
    "    gbm.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50),\n",
    "                    lgb.log_evaluation(period=50, show_stdv=True)])\n",
    "    \n",
    "    gbm_list.append(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('rmse', 5205.2440958930765), ('l2', 27094566.09782974)]), 'valid_1': OrderedDict([('rmse', 6156.852579249154), ('l2', 37906833.68260696)])})\n",
      "defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('rmse', 5206.426318134855), ('l2', 27106875.006167267)]), 'valid_1': OrderedDict([('rmse', 6125.788312370296), ('l2', 37525282.447972514)])})\n",
      "defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('rmse', 5199.173867131504), ('l2', 27031408.900663164)]), 'valid_1': OrderedDict([('rmse', 6159.627756618054), ('l2', 37941014.10009957)])})\n",
      "defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('rmse', 5208.129284664733), ('l2', 27124610.645782374)]), 'valid_1': OrderedDict([('rmse', 6069.698534871405), ('l2', 36841240.30422008)])})\n",
      "defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('rmse', 5201.1759322568605), ('l2', 27052231.078288015)]), 'valid_1': OrderedDict([('rmse', 6125.7809917384275), ('l2', 37525192.75874384)])})\n"
     ]
    }
   ],
   "source": [
    "for e in gbm_list:\n",
    "    print(e.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_after2021['target']\n",
    "X = df_train_after2021.drop(['target', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1623\n",
      "[LightGBM] [Info] Number of data points in the train set: 58303, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 102978.207622\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 38589.5\ttraining's l2: 1.48915e+09\tvalid_1's rmse: 38857.9\tvalid_1's l2: 1.50993e+09\n",
      "[20]\ttraining's rmse: 25096.1\ttraining's l2: 6.29813e+08\tvalid_1's rmse: 25532\tvalid_1's l2: 6.51883e+08\n",
      "[30]\ttraining's rmse: 20732.1\ttraining's l2: 4.2982e+08\tvalid_1's rmse: 21302.9\tvalid_1's l2: 4.53815e+08\n",
      "[40]\ttraining's rmse: 18890.1\ttraining's l2: 3.56835e+08\tvalid_1's rmse: 19626.2\tvalid_1's l2: 3.85188e+08\n",
      "[50]\ttraining's rmse: 17790.5\ttraining's l2: 3.16503e+08\tvalid_1's rmse: 18717.5\tvalid_1's l2: 3.50345e+08\n",
      "[60]\ttraining's rmse: 17030\ttraining's l2: 2.90021e+08\tvalid_1's rmse: 18114.8\tvalid_1's l2: 3.28145e+08\n",
      "[70]\ttraining's rmse: 16420.7\ttraining's l2: 2.69639e+08\tvalid_1's rmse: 17614.4\tvalid_1's l2: 3.10266e+08\n",
      "[80]\ttraining's rmse: 15941.1\ttraining's l2: 2.54119e+08\tvalid_1's rmse: 17279.3\tvalid_1's l2: 2.98573e+08\n",
      "[90]\ttraining's rmse: 15510.3\ttraining's l2: 2.4057e+08\tvalid_1's rmse: 16963.9\tvalid_1's l2: 2.87774e+08\n",
      "[100]\ttraining's rmse: 15129.6\ttraining's l2: 2.28904e+08\tvalid_1's rmse: 16714.6\tvalid_1's l2: 2.79378e+08\n",
      "[110]\ttraining's rmse: 14836.3\ttraining's l2: 2.20117e+08\tvalid_1's rmse: 16532.6\tvalid_1's l2: 2.73328e+08\n",
      "[120]\ttraining's rmse: 14540.1\ttraining's l2: 2.11415e+08\tvalid_1's rmse: 16356.6\tvalid_1's l2: 2.67537e+08\n",
      "[130]\ttraining's rmse: 14302.2\ttraining's l2: 2.04552e+08\tvalid_1's rmse: 16202.7\tvalid_1's l2: 2.62527e+08\n",
      "[140]\ttraining's rmse: 14066.2\ttraining's l2: 1.97858e+08\tvalid_1's rmse: 16060.2\tvalid_1's l2: 2.57929e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttraining's rmse: 13857.6\ttraining's l2: 1.92033e+08\tvalid_1's rmse: 15925.6\tvalid_1's l2: 2.53625e+08\n",
      "[160]\ttraining's rmse: 13693.7\ttraining's l2: 1.87518e+08\tvalid_1's rmse: 15841.7\tvalid_1's l2: 2.5096e+08\n",
      "[170]\ttraining's rmse: 13487.6\ttraining's l2: 1.81916e+08\tvalid_1's rmse: 15728.5\tvalid_1's l2: 2.47387e+08\n",
      "[180]\ttraining's rmse: 13316.9\ttraining's l2: 1.77339e+08\tvalid_1's rmse: 15647.2\tvalid_1's l2: 2.44835e+08\n",
      "[190]\ttraining's rmse: 13144.4\ttraining's l2: 1.72775e+08\tvalid_1's rmse: 15575.6\tvalid_1's l2: 2.42599e+08\n",
      "[200]\ttraining's rmse: 12974.7\ttraining's l2: 1.68343e+08\tvalid_1's rmse: 15488.8\tvalid_1's l2: 2.39904e+08\n",
      "[210]\ttraining's rmse: 12808\ttraining's l2: 1.64045e+08\tvalid_1's rmse: 15398\tvalid_1's l2: 2.37099e+08\n",
      "[220]\ttraining's rmse: 12664.3\ttraining's l2: 1.60386e+08\tvalid_1's rmse: 15329.4\tvalid_1's l2: 2.34989e+08\n",
      "[230]\ttraining's rmse: 12543.2\ttraining's l2: 1.57333e+08\tvalid_1's rmse: 15273.1\tvalid_1's l2: 2.33268e+08\n",
      "[240]\ttraining's rmse: 12401.2\ttraining's l2: 1.53791e+08\tvalid_1's rmse: 15199.8\tvalid_1's l2: 2.31035e+08\n",
      "[250]\ttraining's rmse: 12291.2\ttraining's l2: 1.51074e+08\tvalid_1's rmse: 15136.1\tvalid_1's l2: 2.291e+08\n",
      "[260]\ttraining's rmse: 12199.1\ttraining's l2: 1.48818e+08\tvalid_1's rmse: 15088\tvalid_1's l2: 2.27648e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[270]\ttraining's rmse: 12108.7\ttraining's l2: 1.46622e+08\tvalid_1's rmse: 15054.8\tvalid_1's l2: 2.26647e+08\n",
      "[280]\ttraining's rmse: 12012.5\ttraining's l2: 1.443e+08\tvalid_1's rmse: 15002.7\tvalid_1's l2: 2.25081e+08\n",
      "[290]\ttraining's rmse: 11911.4\ttraining's l2: 1.41882e+08\tvalid_1's rmse: 14968.4\tvalid_1's l2: 2.24052e+08\n",
      "[300]\ttraining's rmse: 11812.8\ttraining's l2: 1.39543e+08\tvalid_1's rmse: 14923.8\tvalid_1's l2: 2.22719e+08\n",
      "[310]\ttraining's rmse: 11724.4\ttraining's l2: 1.37461e+08\tvalid_1's rmse: 14873.3\tvalid_1's l2: 2.21216e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[320]\ttraining's rmse: 11643.4\ttraining's l2: 1.3557e+08\tvalid_1's rmse: 14851.9\tvalid_1's l2: 2.20579e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[330]\ttraining's rmse: 11560.1\ttraining's l2: 1.33635e+08\tvalid_1's rmse: 14819.9\tvalid_1's l2: 2.19628e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[340]\ttraining's rmse: 11483.9\ttraining's l2: 1.31881e+08\tvalid_1's rmse: 14792\tvalid_1's l2: 2.18804e+08\n",
      "[350]\ttraining's rmse: 11419.7\ttraining's l2: 1.3041e+08\tvalid_1's rmse: 14761.3\tvalid_1's l2: 2.17897e+08\n",
      "[360]\ttraining's rmse: 11330.6\ttraining's l2: 1.28382e+08\tvalid_1's rmse: 14724.7\tvalid_1's l2: 2.16816e+08\n",
      "[370]\ttraining's rmse: 11256.3\ttraining's l2: 1.26704e+08\tvalid_1's rmse: 14694\tvalid_1's l2: 2.15914e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[380]\ttraining's rmse: 11185.7\ttraining's l2: 1.25121e+08\tvalid_1's rmse: 14672.3\tvalid_1's l2: 2.15276e+08\n",
      "[390]\ttraining's rmse: 11109.3\ttraining's l2: 1.23416e+08\tvalid_1's rmse: 14637.8\tvalid_1's l2: 2.14267e+08\n",
      "[400]\ttraining's rmse: 11046\ttraining's l2: 1.22014e+08\tvalid_1's rmse: 14614.1\tvalid_1's l2: 2.13573e+08\n",
      "[410]\ttraining's rmse: 10991.3\ttraining's l2: 1.2081e+08\tvalid_1's rmse: 14597.1\tvalid_1's l2: 2.13074e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[420]\ttraining's rmse: 10924.8\ttraining's l2: 1.19351e+08\tvalid_1's rmse: 14577.8\tvalid_1's l2: 2.12513e+08\n",
      "[430]\ttraining's rmse: 10858.6\ttraining's l2: 1.1791e+08\tvalid_1's rmse: 14550.3\tvalid_1's l2: 2.11712e+08\n",
      "[440]\ttraining's rmse: 10791.1\ttraining's l2: 1.16447e+08\tvalid_1's rmse: 14535.8\tvalid_1's l2: 2.11289e+08\n",
      "[450]\ttraining's rmse: 10725.8\ttraining's l2: 1.15043e+08\tvalid_1's rmse: 14508\tvalid_1's l2: 2.10482e+08\n",
      "[460]\ttraining's rmse: 10665.3\ttraining's l2: 1.13748e+08\tvalid_1's rmse: 14486.3\tvalid_1's l2: 2.09853e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[470]\ttraining's rmse: 10611.4\ttraining's l2: 1.12601e+08\tvalid_1's rmse: 14467.5\tvalid_1's l2: 2.09307e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[480]\ttraining's rmse: 10555.6\ttraining's l2: 1.11422e+08\tvalid_1's rmse: 14456\tvalid_1's l2: 2.08977e+08\n",
      "[490]\ttraining's rmse: 10506.6\ttraining's l2: 1.10388e+08\tvalid_1's rmse: 14433.6\tvalid_1's l2: 2.08329e+08\n",
      "[500]\ttraining's rmse: 10450.5\ttraining's l2: 1.09213e+08\tvalid_1's rmse: 14417.6\tvalid_1's l2: 2.07866e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[510]\ttraining's rmse: 10396.2\ttraining's l2: 1.0808e+08\tvalid_1's rmse: 14398\tvalid_1's l2: 2.07303e+08\n",
      "[520]\ttraining's rmse: 10336.4\ttraining's l2: 1.06842e+08\tvalid_1's rmse: 14384.4\tvalid_1's l2: 2.06912e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[530]\ttraining's rmse: 10286.6\ttraining's l2: 1.05813e+08\tvalid_1's rmse: 14369.6\tvalid_1's l2: 2.06486e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[540]\ttraining's rmse: 10235.7\ttraining's l2: 1.04769e+08\tvalid_1's rmse: 14366.1\tvalid_1's l2: 2.06384e+08\n",
      "[550]\ttraining's rmse: 10188.9\ttraining's l2: 1.03815e+08\tvalid_1's rmse: 14357\tvalid_1's l2: 2.06123e+08\n",
      "[560]\ttraining's rmse: 10130.5\ttraining's l2: 1.02627e+08\tvalid_1's rmse: 14344.3\tvalid_1's l2: 2.05758e+08\n",
      "[570]\ttraining's rmse: 10088.9\ttraining's l2: 1.01787e+08\tvalid_1's rmse: 14334.3\tvalid_1's l2: 2.05473e+08\n",
      "[580]\ttraining's rmse: 10044\ttraining's l2: 1.00883e+08\tvalid_1's rmse: 14318.3\tvalid_1's l2: 2.05015e+08\n",
      "[590]\ttraining's rmse: 10005.3\ttraining's l2: 1.00106e+08\tvalid_1's rmse: 14307.3\tvalid_1's l2: 2.04699e+08\n",
      "[600]\ttraining's rmse: 9955.97\ttraining's l2: 9.91213e+07\tvalid_1's rmse: 14303.6\tvalid_1's l2: 2.04592e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[610]\ttraining's rmse: 9915.56\ttraining's l2: 9.83183e+07\tvalid_1's rmse: 14290.3\tvalid_1's l2: 2.04212e+08\n",
      "[620]\ttraining's rmse: 9872.96\ttraining's l2: 9.74754e+07\tvalid_1's rmse: 14283.7\tvalid_1's l2: 2.04024e+08\n",
      "[630]\ttraining's rmse: 9832.92\ttraining's l2: 9.66863e+07\tvalid_1's rmse: 14273.9\tvalid_1's l2: 2.03743e+08\n",
      "[640]\ttraining's rmse: 9799.25\ttraining's l2: 9.60254e+07\tvalid_1's rmse: 14261.5\tvalid_1's l2: 2.03391e+08\n",
      "[650]\ttraining's rmse: 9761.05\ttraining's l2: 9.52781e+07\tvalid_1's rmse: 14249.7\tvalid_1's l2: 2.03054e+08\n",
      "[660]\ttraining's rmse: 9719.62\ttraining's l2: 9.44709e+07\tvalid_1's rmse: 14241\tvalid_1's l2: 2.02806e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[670]\ttraining's rmse: 9689.69\ttraining's l2: 9.38901e+07\tvalid_1's rmse: 14234.3\tvalid_1's l2: 2.02616e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[680]\ttraining's rmse: 9650.75\ttraining's l2: 9.3137e+07\tvalid_1's rmse: 14227.1\tvalid_1's l2: 2.02411e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[690]\ttraining's rmse: 9615.43\ttraining's l2: 9.24564e+07\tvalid_1's rmse: 14226.6\tvalid_1's l2: 2.02395e+08\n",
      "[700]\ttraining's rmse: 9574.25\ttraining's l2: 9.16663e+07\tvalid_1's rmse: 14228.1\tvalid_1's l2: 2.02439e+08\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's rmse: 9611.04\ttraining's l2: 9.2372e+07\tvalid_1's rmse: 14225.3\tvalid_1's l2: 2.0236e+08\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1622\n",
      "[LightGBM] [Info] Number of data points in the train set: 58303, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 102830.735743\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 38335.1\ttraining's l2: 1.46958e+09\tvalid_1's rmse: 40020.4\tvalid_1's l2: 1.60163e+09\n",
      "[20]\ttraining's rmse: 25046.3\ttraining's l2: 6.27316e+08\tvalid_1's rmse: 26503.5\tvalid_1's l2: 7.02436e+08\n",
      "[30]\ttraining's rmse: 20701.4\ttraining's l2: 4.28549e+08\tvalid_1's rmse: 22315.5\tvalid_1's l2: 4.97982e+08\n",
      "[40]\ttraining's rmse: 18920.5\ttraining's l2: 3.57984e+08\tvalid_1's rmse: 20587.1\tvalid_1's l2: 4.2383e+08\n",
      "[50]\ttraining's rmse: 17822.1\ttraining's l2: 3.17628e+08\tvalid_1's rmse: 19568.9\tvalid_1's l2: 3.82942e+08\n",
      "[60]\ttraining's rmse: 17030.6\ttraining's l2: 2.90043e+08\tvalid_1's rmse: 18870\tvalid_1's l2: 3.56075e+08\n",
      "[70]\ttraining's rmse: 16435.6\ttraining's l2: 2.70128e+08\tvalid_1's rmse: 18377.7\tvalid_1's l2: 3.3774e+08\n",
      "[80]\ttraining's rmse: 15974.4\ttraining's l2: 2.5518e+08\tvalid_1's rmse: 18026\tvalid_1's l2: 3.24937e+08\n",
      "[90]\ttraining's rmse: 15516.7\ttraining's l2: 2.40769e+08\tvalid_1's rmse: 17604.6\tvalid_1's l2: 3.09922e+08\n",
      "[100]\ttraining's rmse: 15201.5\ttraining's l2: 2.31086e+08\tvalid_1's rmse: 17351.9\tvalid_1's l2: 3.01087e+08\n",
      "[110]\ttraining's rmse: 14899.7\ttraining's l2: 2.22002e+08\tvalid_1's rmse: 17151.5\tvalid_1's l2: 2.94175e+08\n",
      "[120]\ttraining's rmse: 14615.8\ttraining's l2: 2.13622e+08\tvalid_1's rmse: 16936.4\tvalid_1's l2: 2.86841e+08\n",
      "[130]\ttraining's rmse: 14360\ttraining's l2: 2.06209e+08\tvalid_1's rmse: 16778.1\tvalid_1's l2: 2.81506e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttraining's rmse: 14146.4\ttraining's l2: 2.00119e+08\tvalid_1's rmse: 16624.6\tvalid_1's l2: 2.76378e+08\n",
      "[150]\ttraining's rmse: 13914.7\ttraining's l2: 1.93618e+08\tvalid_1's rmse: 16474\tvalid_1's l2: 2.71392e+08\n",
      "[160]\ttraining's rmse: 13709\ttraining's l2: 1.87935e+08\tvalid_1's rmse: 16341.8\tvalid_1's l2: 2.67053e+08\n",
      "[170]\ttraining's rmse: 13531.7\ttraining's l2: 1.83107e+08\tvalid_1's rmse: 16239.5\tvalid_1's l2: 2.63721e+08\n",
      "[180]\ttraining's rmse: 13357.7\ttraining's l2: 1.78428e+08\tvalid_1's rmse: 16145.1\tvalid_1's l2: 2.60663e+08\n",
      "[190]\ttraining's rmse: 13188.1\ttraining's l2: 1.73927e+08\tvalid_1's rmse: 16037.8\tvalid_1's l2: 2.5721e+08\n",
      "[200]\ttraining's rmse: 13048.8\ttraining's l2: 1.70271e+08\tvalid_1's rmse: 15954.6\tvalid_1's l2: 2.54549e+08\n",
      "[210]\ttraining's rmse: 12896.9\ttraining's l2: 1.6633e+08\tvalid_1's rmse: 15855.8\tvalid_1's l2: 2.51406e+08\n",
      "[220]\ttraining's rmse: 12747.7\ttraining's l2: 1.62504e+08\tvalid_1's rmse: 15780.5\tvalid_1's l2: 2.49025e+08\n",
      "[230]\ttraining's rmse: 12606.8\ttraining's l2: 1.58932e+08\tvalid_1's rmse: 15682.8\tvalid_1's l2: 2.4595e+08\n",
      "[240]\ttraining's rmse: 12484.2\ttraining's l2: 1.55855e+08\tvalid_1's rmse: 15612.3\tvalid_1's l2: 2.43744e+08\n",
      "[250]\ttraining's rmse: 12366\ttraining's l2: 1.52917e+08\tvalid_1's rmse: 15554.2\tvalid_1's l2: 2.41933e+08\n",
      "[260]\ttraining's rmse: 12256\ttraining's l2: 1.50209e+08\tvalid_1's rmse: 15491.6\tvalid_1's l2: 2.3999e+08\n",
      "[270]\ttraining's rmse: 12146.8\ttraining's l2: 1.47544e+08\tvalid_1's rmse: 15433.1\tvalid_1's l2: 2.38182e+08\n",
      "[280]\ttraining's rmse: 12021.2\ttraining's l2: 1.44508e+08\tvalid_1's rmse: 15376.1\tvalid_1's l2: 2.36425e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[290]\ttraining's rmse: 11916.4\ttraining's l2: 1.42001e+08\tvalid_1's rmse: 15323.4\tvalid_1's l2: 2.34807e+08\n",
      "[300]\ttraining's rmse: 11827.6\ttraining's l2: 1.39891e+08\tvalid_1's rmse: 15270.7\tvalid_1's l2: 2.33195e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[310]\ttraining's rmse: 11731.7\ttraining's l2: 1.37633e+08\tvalid_1's rmse: 15229.9\tvalid_1's l2: 2.3195e+08\n",
      "[320]\ttraining's rmse: 11629.9\ttraining's l2: 1.35255e+08\tvalid_1's rmse: 15184.2\tvalid_1's l2: 2.30561e+08\n",
      "[330]\ttraining's rmse: 11541.4\ttraining's l2: 1.33203e+08\tvalid_1's rmse: 15156.5\tvalid_1's l2: 2.29721e+08\n",
      "[340]\ttraining's rmse: 11460\ttraining's l2: 1.31332e+08\tvalid_1's rmse: 15132.5\tvalid_1's l2: 2.28993e+08\n",
      "[350]\ttraining's rmse: 11365\ttraining's l2: 1.29163e+08\tvalid_1's rmse: 15091\tvalid_1's l2: 2.27737e+08\n",
      "[360]\ttraining's rmse: 11285.3\ttraining's l2: 1.27358e+08\tvalid_1's rmse: 15057.7\tvalid_1's l2: 2.26733e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[370]\ttraining's rmse: 11214.6\ttraining's l2: 1.25767e+08\tvalid_1's rmse: 15038.8\tvalid_1's l2: 2.26167e+08\n",
      "[380]\ttraining's rmse: 11136.9\ttraining's l2: 1.2403e+08\tvalid_1's rmse: 15008.7\tvalid_1's l2: 2.25261e+08\n",
      "[390]\ttraining's rmse: 11068.9\ttraining's l2: 1.2252e+08\tvalid_1's rmse: 14996.7\tvalid_1's l2: 2.24901e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's rmse: 10989.7\ttraining's l2: 1.20774e+08\tvalid_1's rmse: 14969\tvalid_1's l2: 2.24072e+08\n",
      "[410]\ttraining's rmse: 10920.5\ttraining's l2: 1.19257e+08\tvalid_1's rmse: 14964.9\tvalid_1's l2: 2.23948e+08\n",
      "[420]\ttraining's rmse: 10862.5\ttraining's l2: 1.17993e+08\tvalid_1's rmse: 14952.8\tvalid_1's l2: 2.23587e+08\n",
      "[430]\ttraining's rmse: 10801\ttraining's l2: 1.16661e+08\tvalid_1's rmse: 14928.4\tvalid_1's l2: 2.22857e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[440]\ttraining's rmse: 10733.5\ttraining's l2: 1.15207e+08\tvalid_1's rmse: 14905.7\tvalid_1's l2: 2.2218e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\ttraining's rmse: 10667.2\ttraining's l2: 1.13788e+08\tvalid_1's rmse: 14879.5\tvalid_1's l2: 2.214e+08\n",
      "[460]\ttraining's rmse: 10608.9\ttraining's l2: 1.1255e+08\tvalid_1's rmse: 14866.3\tvalid_1's l2: 2.21006e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[470]\ttraining's rmse: 10549.6\ttraining's l2: 1.11294e+08\tvalid_1's rmse: 14858.9\tvalid_1's l2: 2.20786e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[480]\ttraining's rmse: 10490.1\ttraining's l2: 1.10042e+08\tvalid_1's rmse: 14852.3\tvalid_1's l2: 2.2059e+08\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttraining's rmse: 10511.4\ttraining's l2: 1.10489e+08\tvalid_1's rmse: 14843.5\tvalid_1's l2: 2.20331e+08\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1621\n",
      "[LightGBM] [Info] Number of data points in the train set: 58303, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 103057.900605\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 38409.8\ttraining's l2: 1.47531e+09\tvalid_1's rmse: 39097.7\tvalid_1's l2: 1.52863e+09\n",
      "[20]\ttraining's rmse: 24780\ttraining's l2: 6.1405e+08\tvalid_1's rmse: 26379.4\tvalid_1's l2: 6.95874e+08\n",
      "[30]\ttraining's rmse: 20446.2\ttraining's l2: 4.18048e+08\tvalid_1's rmse: 22524.4\tvalid_1's l2: 5.07348e+08\n",
      "[40]\ttraining's rmse: 18602.5\ttraining's l2: 3.46053e+08\tvalid_1's rmse: 20882.8\tvalid_1's l2: 4.3609e+08\n",
      "[50]\ttraining's rmse: 17534.5\ttraining's l2: 3.07459e+08\tvalid_1's rmse: 19947.6\tvalid_1's l2: 3.97907e+08\n",
      "[60]\ttraining's rmse: 16734.7\ttraining's l2: 2.80051e+08\tvalid_1's rmse: 19339.3\tvalid_1's l2: 3.74008e+08\n",
      "[70]\ttraining's rmse: 16142.7\ttraining's l2: 2.60586e+08\tvalid_1's rmse: 18877\tvalid_1's l2: 3.5634e+08\n",
      "[80]\ttraining's rmse: 15659.1\ttraining's l2: 2.45208e+08\tvalid_1's rmse: 18474.8\tvalid_1's l2: 3.41319e+08\n",
      "[90]\ttraining's rmse: 15270.2\ttraining's l2: 2.33179e+08\tvalid_1's rmse: 18162.1\tvalid_1's l2: 3.29861e+08\n",
      "[100]\ttraining's rmse: 14939.8\ttraining's l2: 2.23197e+08\tvalid_1's rmse: 17902.7\tvalid_1's l2: 3.20506e+08\n",
      "[110]\ttraining's rmse: 14642.1\ttraining's l2: 2.14392e+08\tvalid_1's rmse: 17713.7\tvalid_1's l2: 3.13777e+08\n",
      "[120]\ttraining's rmse: 14364.7\ttraining's l2: 2.06344e+08\tvalid_1's rmse: 17518.9\tvalid_1's l2: 3.06913e+08\n",
      "[130]\ttraining's rmse: 14138.9\ttraining's l2: 1.99909e+08\tvalid_1's rmse: 17359.2\tvalid_1's l2: 3.01342e+08\n",
      "[140]\ttraining's rmse: 13931.9\ttraining's l2: 1.94098e+08\tvalid_1's rmse: 17236.3\tvalid_1's l2: 2.97091e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttraining's rmse: 13753.7\ttraining's l2: 1.89163e+08\tvalid_1's rmse: 17113\tvalid_1's l2: 2.92855e+08\n",
      "[160]\ttraining's rmse: 13568.2\ttraining's l2: 1.84097e+08\tvalid_1's rmse: 16974.8\tvalid_1's l2: 2.88143e+08\n",
      "[170]\ttraining's rmse: 13384\ttraining's l2: 1.7913e+08\tvalid_1's rmse: 16849.7\tvalid_1's l2: 2.83912e+08\n",
      "[180]\ttraining's rmse: 13215.4\ttraining's l2: 1.74646e+08\tvalid_1's rmse: 16755.9\tvalid_1's l2: 2.8076e+08\n",
      "[190]\ttraining's rmse: 13075\ttraining's l2: 1.70955e+08\tvalid_1's rmse: 16659.9\tvalid_1's l2: 2.77553e+08\n",
      "[200]\ttraining's rmse: 12926.7\ttraining's l2: 1.67101e+08\tvalid_1's rmse: 16582.4\tvalid_1's l2: 2.74977e+08\n",
      "[210]\ttraining's rmse: 12788.8\ttraining's l2: 1.63554e+08\tvalid_1's rmse: 16500.9\tvalid_1's l2: 2.72281e+08\n",
      "[220]\ttraining's rmse: 12670\ttraining's l2: 1.60529e+08\tvalid_1's rmse: 16437\tvalid_1's l2: 2.70175e+08\n",
      "[230]\ttraining's rmse: 12550.8\ttraining's l2: 1.57522e+08\tvalid_1's rmse: 16354.2\tvalid_1's l2: 2.67458e+08\n",
      "[240]\ttraining's rmse: 12424.4\ttraining's l2: 1.54365e+08\tvalid_1's rmse: 16275.9\tvalid_1's l2: 2.64907e+08\n",
      "[250]\ttraining's rmse: 12324.4\ttraining's l2: 1.51891e+08\tvalid_1's rmse: 16219.9\tvalid_1's l2: 2.63085e+08\n",
      "[260]\ttraining's rmse: 12205.8\ttraining's l2: 1.48982e+08\tvalid_1's rmse: 16145.3\tvalid_1's l2: 2.60672e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[270]\ttraining's rmse: 12114.8\ttraining's l2: 1.46769e+08\tvalid_1's rmse: 16094.3\tvalid_1's l2: 2.59026e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[280]\ttraining's rmse: 12020\ttraining's l2: 1.44481e+08\tvalid_1's rmse: 16034\tvalid_1's l2: 2.57088e+08\n",
      "[290]\ttraining's rmse: 11934.5\ttraining's l2: 1.42433e+08\tvalid_1's rmse: 15984\tvalid_1's l2: 2.55488e+08\n",
      "[300]\ttraining's rmse: 11830.7\ttraining's l2: 1.39964e+08\tvalid_1's rmse: 15927.5\tvalid_1's l2: 2.53685e+08\n",
      "[310]\ttraining's rmse: 11744.1\ttraining's l2: 1.37923e+08\tvalid_1's rmse: 15876.3\tvalid_1's l2: 2.52058e+08\n",
      "[320]\ttraining's rmse: 11654.2\ttraining's l2: 1.35821e+08\tvalid_1's rmse: 15835.6\tvalid_1's l2: 2.50766e+08\n",
      "[330]\ttraining's rmse: 11564.9\ttraining's l2: 1.33748e+08\tvalid_1's rmse: 15796.6\tvalid_1's l2: 2.49534e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[340]\ttraining's rmse: 11487.9\ttraining's l2: 1.31971e+08\tvalid_1's rmse: 15757.7\tvalid_1's l2: 2.48306e+08\n",
      "[350]\ttraining's rmse: 11420.9\ttraining's l2: 1.30436e+08\tvalid_1's rmse: 15722.1\tvalid_1's l2: 2.47186e+08\n",
      "[360]\ttraining's rmse: 11341.6\ttraining's l2: 1.28633e+08\tvalid_1's rmse: 15677.7\tvalid_1's l2: 2.45791e+08\n",
      "[370]\ttraining's rmse: 11269.1\ttraining's l2: 1.26993e+08\tvalid_1's rmse: 15638.5\tvalid_1's l2: 2.44563e+08\n",
      "[380]\ttraining's rmse: 11196.9\ttraining's l2: 1.25371e+08\tvalid_1's rmse: 15606.5\tvalid_1's l2: 2.43563e+08\n",
      "[390]\ttraining's rmse: 11119.5\ttraining's l2: 1.23643e+08\tvalid_1's rmse: 15572.8\tvalid_1's l2: 2.42511e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's rmse: 11045.4\ttraining's l2: 1.22002e+08\tvalid_1's rmse: 15516.6\tvalid_1's l2: 2.40765e+08\n",
      "[410]\ttraining's rmse: 10978.7\ttraining's l2: 1.20533e+08\tvalid_1's rmse: 15490.5\tvalid_1's l2: 2.39956e+08\n",
      "[420]\ttraining's rmse: 10909\ttraining's l2: 1.19006e+08\tvalid_1's rmse: 15461.6\tvalid_1's l2: 2.39061e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[430]\ttraining's rmse: 10845.9\ttraining's l2: 1.17634e+08\tvalid_1's rmse: 15432.7\tvalid_1's l2: 2.38169e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[440]\ttraining's rmse: 10778.2\ttraining's l2: 1.1617e+08\tvalid_1's rmse: 15415.1\tvalid_1's l2: 2.37627e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\ttraining's rmse: 10718.8\ttraining's l2: 1.14892e+08\tvalid_1's rmse: 15383.1\tvalid_1's l2: 2.3664e+08\n",
      "[460]\ttraining's rmse: 10673.3\ttraining's l2: 1.1392e+08\tvalid_1's rmse: 15357.7\tvalid_1's l2: 2.3586e+08\n",
      "[470]\ttraining's rmse: 10617.2\ttraining's l2: 1.12726e+08\tvalid_1's rmse: 15339.9\tvalid_1's l2: 2.35313e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[480]\ttraining's rmse: 10563.8\ttraining's l2: 1.11595e+08\tvalid_1's rmse: 15327.9\tvalid_1's l2: 2.34946e+08\n",
      "[490]\ttraining's rmse: 10514.1\ttraining's l2: 1.10546e+08\tvalid_1's rmse: 15302.6\tvalid_1's l2: 2.3417e+08\n",
      "[500]\ttraining's rmse: 10461.7\ttraining's l2: 1.09447e+08\tvalid_1's rmse: 15270.1\tvalid_1's l2: 2.33175e+08\n",
      "[510]\ttraining's rmse: 10408.7\ttraining's l2: 1.0834e+08\tvalid_1's rmse: 15261\tvalid_1's l2: 2.32898e+08\n",
      "[520]\ttraining's rmse: 10363\ttraining's l2: 1.07391e+08\tvalid_1's rmse: 15237.4\tvalid_1's l2: 2.32178e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[530]\ttraining's rmse: 10315.5\ttraining's l2: 1.0641e+08\tvalid_1's rmse: 15212.6\tvalid_1's l2: 2.31423e+08\n",
      "[540]\ttraining's rmse: 10261.8\ttraining's l2: 1.05305e+08\tvalid_1's rmse: 15184.8\tvalid_1's l2: 2.30578e+08\n",
      "[550]\ttraining's rmse: 10211.2\ttraining's l2: 1.04268e+08\tvalid_1's rmse: 15164.5\tvalid_1's l2: 2.29962e+08\n",
      "[560]\ttraining's rmse: 10161.6\ttraining's l2: 1.03258e+08\tvalid_1's rmse: 15147\tvalid_1's l2: 2.29432e+08\n",
      "[570]\ttraining's rmse: 10119.7\ttraining's l2: 1.02409e+08\tvalid_1's rmse: 15127.8\tvalid_1's l2: 2.28851e+08\n",
      "[580]\ttraining's rmse: 10074.7\ttraining's l2: 1.01499e+08\tvalid_1's rmse: 15107\tvalid_1's l2: 2.28221e+08\n",
      "[590]\ttraining's rmse: 10035.9\ttraining's l2: 1.00719e+08\tvalid_1's rmse: 15083.3\tvalid_1's l2: 2.27505e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\ttraining's rmse: 9991.45\ttraining's l2: 9.9829e+07\tvalid_1's rmse: 15071.8\tvalid_1's l2: 2.27159e+08\n",
      "[610]\ttraining's rmse: 9955.93\ttraining's l2: 9.91206e+07\tvalid_1's rmse: 15063.2\tvalid_1's l2: 2.26901e+08\n",
      "[620]\ttraining's rmse: 9918.2\ttraining's l2: 9.83706e+07\tvalid_1's rmse: 15050\tvalid_1's l2: 2.26503e+08\n",
      "[630]\ttraining's rmse: 9875.64\ttraining's l2: 9.75282e+07\tvalid_1's rmse: 15030.1\tvalid_1's l2: 2.25904e+08\n",
      "[640]\ttraining's rmse: 9836.96\ttraining's l2: 9.67657e+07\tvalid_1's rmse: 15016.7\tvalid_1's l2: 2.255e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[650]\ttraining's rmse: 9807.78\ttraining's l2: 9.61926e+07\tvalid_1's rmse: 15007.3\tvalid_1's l2: 2.25218e+08\n",
      "[660]\ttraining's rmse: 9771.4\ttraining's l2: 9.54802e+07\tvalid_1's rmse: 14997.4\tvalid_1's l2: 2.24921e+08\n",
      "[670]\ttraining's rmse: 9726.12\ttraining's l2: 9.45973e+07\tvalid_1's rmse: 14981.2\tvalid_1's l2: 2.24437e+08\n",
      "[680]\ttraining's rmse: 9688.73\ttraining's l2: 9.38714e+07\tvalid_1's rmse: 14973.6\tvalid_1's l2: 2.24208e+08\n",
      "[690]\ttraining's rmse: 9649.45\ttraining's l2: 9.31118e+07\tvalid_1's rmse: 14962.1\tvalid_1's l2: 2.23865e+08\n",
      "[700]\ttraining's rmse: 9607.14\ttraining's l2: 9.22972e+07\tvalid_1's rmse: 14952.8\tvalid_1's l2: 2.23586e+08\n",
      "[710]\ttraining's rmse: 9571.27\ttraining's l2: 9.16092e+07\tvalid_1's rmse: 14948.2\tvalid_1's l2: 2.2345e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[720]\ttraining's rmse: 9530.31\ttraining's l2: 9.08267e+07\tvalid_1's rmse: 14936\tvalid_1's l2: 2.23085e+08\n",
      "[730]\ttraining's rmse: 9496.5\ttraining's l2: 9.01834e+07\tvalid_1's rmse: 14915.2\tvalid_1's l2: 2.22462e+08\n",
      "[740]\ttraining's rmse: 9461.54\ttraining's l2: 8.95207e+07\tvalid_1's rmse: 14895.9\tvalid_1's l2: 2.21889e+08\n",
      "[750]\ttraining's rmse: 9429.47\ttraining's l2: 8.89148e+07\tvalid_1's rmse: 14886.8\tvalid_1's l2: 2.21617e+08\n",
      "[760]\ttraining's rmse: 9394.53\ttraining's l2: 8.82572e+07\tvalid_1's rmse: 14873.3\tvalid_1's l2: 2.21214e+08\n",
      "[770]\ttraining's rmse: 9360.53\ttraining's l2: 8.76195e+07\tvalid_1's rmse: 14861.7\tvalid_1's l2: 2.20869e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[780]\ttraining's rmse: 9319.71\ttraining's l2: 8.6857e+07\tvalid_1's rmse: 14850.1\tvalid_1's l2: 2.20524e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[790]\ttraining's rmse: 9286.89\ttraining's l2: 8.62464e+07\tvalid_1's rmse: 14846.5\tvalid_1's l2: 2.20418e+08\n",
      "[800]\ttraining's rmse: 9257.27\ttraining's l2: 8.5697e+07\tvalid_1's rmse: 14830.1\tvalid_1's l2: 2.1993e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[810]\ttraining's rmse: 9227.09\ttraining's l2: 8.51393e+07\tvalid_1's rmse: 14827.4\tvalid_1's l2: 2.19852e+08\n",
      "[820]\ttraining's rmse: 9197.33\ttraining's l2: 8.45909e+07\tvalid_1's rmse: 14814.2\tvalid_1's l2: 2.19459e+08\n",
      "[830]\ttraining's rmse: 9168.81\ttraining's l2: 8.40671e+07\tvalid_1's rmse: 14805.7\tvalid_1's l2: 2.19209e+08\n",
      "[840]\ttraining's rmse: 9145.4\ttraining's l2: 8.36384e+07\tvalid_1's rmse: 14801.3\tvalid_1's l2: 2.19079e+08\n",
      "[850]\ttraining's rmse: 9107.15\ttraining's l2: 8.29402e+07\tvalid_1's rmse: 14782.9\tvalid_1's l2: 2.18534e+08\n",
      "[860]\ttraining's rmse: 9081\ttraining's l2: 8.24645e+07\tvalid_1's rmse: 14770.2\tvalid_1's l2: 2.18159e+08\n",
      "[870]\ttraining's rmse: 9051.61\ttraining's l2: 8.19316e+07\tvalid_1's rmse: 14764\tvalid_1's l2: 2.17977e+08\n",
      "[880]\ttraining's rmse: 9023.56\ttraining's l2: 8.14247e+07\tvalid_1's rmse: 14752.7\tvalid_1's l2: 2.17641e+08\n",
      "[890]\ttraining's rmse: 8992.51\ttraining's l2: 8.08652e+07\tvalid_1's rmse: 14743.8\tvalid_1's l2: 2.17381e+08\n",
      "[900]\ttraining's rmse: 8963.16\ttraining's l2: 8.03383e+07\tvalid_1's rmse: 14739.6\tvalid_1's l2: 2.17255e+08\n",
      "[910]\ttraining's rmse: 8934.84\ttraining's l2: 7.98313e+07\tvalid_1's rmse: 14738\tvalid_1's l2: 2.17209e+08\n",
      "[920]\ttraining's rmse: 8896.43\ttraining's l2: 7.91465e+07\tvalid_1's rmse: 14732.7\tvalid_1's l2: 2.17051e+08\n",
      "[930]\ttraining's rmse: 8872.07\ttraining's l2: 7.87136e+07\tvalid_1's rmse: 14722.4\tvalid_1's l2: 2.16749e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[940]\ttraining's rmse: 8848.48\ttraining's l2: 7.82957e+07\tvalid_1's rmse: 14710.3\tvalid_1's l2: 2.16393e+08\n",
      "[950]\ttraining's rmse: 8820.91\ttraining's l2: 7.78085e+07\tvalid_1's rmse: 14700.7\tvalid_1's l2: 2.16111e+08\n",
      "[960]\ttraining's rmse: 8791.44\ttraining's l2: 7.72894e+07\tvalid_1's rmse: 14692.9\tvalid_1's l2: 2.15883e+08\n",
      "[970]\ttraining's rmse: 8767.19\ttraining's l2: 7.68636e+07\tvalid_1's rmse: 14682.2\tvalid_1's l2: 2.15567e+08\n",
      "[980]\ttraining's rmse: 8741.74\ttraining's l2: 7.64181e+07\tvalid_1's rmse: 14679.6\tvalid_1's l2: 2.15491e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[990]\ttraining's rmse: 8716.52\ttraining's l2: 7.59777e+07\tvalid_1's rmse: 14669.7\tvalid_1's l2: 2.15199e+08\n",
      "[1000]\ttraining's rmse: 8690.52\ttraining's l2: 7.55252e+07\tvalid_1's rmse: 14664.1\tvalid_1's l2: 2.15036e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1010]\ttraining's rmse: 8672.35\ttraining's l2: 7.52096e+07\tvalid_1's rmse: 14654.7\tvalid_1's l2: 2.14759e+08\n",
      "[1020]\ttraining's rmse: 8644.59\ttraining's l2: 7.47289e+07\tvalid_1's rmse: 14650.9\tvalid_1's l2: 2.1465e+08\n",
      "[1030]\ttraining's rmse: 8619.53\ttraining's l2: 7.42963e+07\tvalid_1's rmse: 14643.8\tvalid_1's l2: 2.14441e+08\n",
      "[1040]\ttraining's rmse: 8598.08\ttraining's l2: 7.39269e+07\tvalid_1's rmse: 14638.2\tvalid_1's l2: 2.14276e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1050]\ttraining's rmse: 8577.81\ttraining's l2: 7.35788e+07\tvalid_1's rmse: 14636.1\tvalid_1's l2: 2.14217e+08\n",
      "[1060]\ttraining's rmse: 8556.51\ttraining's l2: 7.32139e+07\tvalid_1's rmse: 14631\tvalid_1's l2: 2.14067e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1070]\ttraining's rmse: 8534.98\ttraining's l2: 7.2846e+07\tvalid_1's rmse: 14625\tvalid_1's l2: 2.1389e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1080]\ttraining's rmse: 8516.36\ttraining's l2: 7.25284e+07\tvalid_1's rmse: 14619.7\tvalid_1's l2: 2.13735e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1090]\ttraining's rmse: 8491.27\ttraining's l2: 7.21016e+07\tvalid_1's rmse: 14621\tvalid_1's l2: 2.13774e+08\n",
      "Early stopping, best iteration is:\n",
      "[1081]\ttraining's rmse: 8514.02\ttraining's l2: 7.24885e+07\tvalid_1's rmse: 14619.3\tvalid_1's l2: 2.13724e+08\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1623\n",
      "[LightGBM] [Info] Number of data points in the train set: 58303, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 103211.897038\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 38650.1\ttraining's l2: 1.49383e+09\tvalid_1's rmse: 37236.6\tvalid_1's l2: 1.38656e+09\n",
      "[20]\ttraining's rmse: 25189.3\ttraining's l2: 6.34501e+08\tvalid_1's rmse: 24132.6\tvalid_1's l2: 5.82384e+08\n",
      "[30]\ttraining's rmse: 20848.8\ttraining's l2: 4.34674e+08\tvalid_1's rmse: 20406.3\tvalid_1's l2: 4.16415e+08\n",
      "[40]\ttraining's rmse: 18950.9\ttraining's l2: 3.59137e+08\tvalid_1's rmse: 19105.2\tvalid_1's l2: 3.65009e+08\n",
      "[50]\ttraining's rmse: 17849\ttraining's l2: 3.18585e+08\tvalid_1's rmse: 18351.5\tvalid_1's l2: 3.36777e+08\n",
      "[60]\ttraining's rmse: 17054.9\ttraining's l2: 2.9087e+08\tvalid_1's rmse: 17849.3\tvalid_1's l2: 3.18598e+08\n",
      "[70]\ttraining's rmse: 16466.6\ttraining's l2: 2.71148e+08\tvalid_1's rmse: 17477.1\tvalid_1's l2: 3.05451e+08\n",
      "[80]\ttraining's rmse: 15956.6\ttraining's l2: 2.54614e+08\tvalid_1's rmse: 17129.7\tvalid_1's l2: 2.93426e+08\n",
      "[90]\ttraining's rmse: 15541.8\ttraining's l2: 2.41548e+08\tvalid_1's rmse: 16827.8\tvalid_1's l2: 2.83173e+08\n",
      "[100]\ttraining's rmse: 15179\ttraining's l2: 2.30403e+08\tvalid_1's rmse: 16623.8\tvalid_1's l2: 2.76349e+08\n",
      "[110]\ttraining's rmse: 14857\ttraining's l2: 2.20729e+08\tvalid_1's rmse: 16417.8\tvalid_1's l2: 2.69545e+08\n",
      "[120]\ttraining's rmse: 14598\ttraining's l2: 2.13101e+08\tvalid_1's rmse: 16259.3\tvalid_1's l2: 2.64365e+08\n",
      "[130]\ttraining's rmse: 14358\ttraining's l2: 2.06151e+08\tvalid_1's rmse: 16122.3\tvalid_1's l2: 2.59927e+08\n",
      "[140]\ttraining's rmse: 14138.8\ttraining's l2: 1.99905e+08\tvalid_1's rmse: 16017.6\tvalid_1's l2: 2.56563e+08\n",
      "[150]\ttraining's rmse: 13923.9\ttraining's l2: 1.93874e+08\tvalid_1's rmse: 15865.3\tvalid_1's l2: 2.51706e+08\n",
      "[160]\ttraining's rmse: 13734.6\ttraining's l2: 1.8864e+08\tvalid_1's rmse: 15772\tvalid_1's l2: 2.48757e+08\n",
      "[170]\ttraining's rmse: 13538.4\ttraining's l2: 1.83288e+08\tvalid_1's rmse: 15656\tvalid_1's l2: 2.45111e+08\n",
      "[180]\ttraining's rmse: 13383.2\ttraining's l2: 1.79111e+08\tvalid_1's rmse: 15576\tvalid_1's l2: 2.42612e+08\n",
      "[190]\ttraining's rmse: 13200.6\ttraining's l2: 1.74257e+08\tvalid_1's rmse: 15475.6\tvalid_1's l2: 2.39493e+08\n",
      "[200]\ttraining's rmse: 13056.5\ttraining's l2: 1.70472e+08\tvalid_1's rmse: 15394.9\tvalid_1's l2: 2.37002e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[210]\ttraining's rmse: 12915\ttraining's l2: 1.66798e+08\tvalid_1's rmse: 15326.9\tvalid_1's l2: 2.34915e+08\n",
      "[220]\ttraining's rmse: 12760.6\ttraining's l2: 1.62833e+08\tvalid_1's rmse: 15228.3\tvalid_1's l2: 2.31901e+08\n",
      "[230]\ttraining's rmse: 12642\ttraining's l2: 1.59819e+08\tvalid_1's rmse: 15175.6\tvalid_1's l2: 2.303e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[240]\ttraining's rmse: 12525.8\ttraining's l2: 1.56896e+08\tvalid_1's rmse: 15106.9\tvalid_1's l2: 2.28218e+08\n",
      "[250]\ttraining's rmse: 12429.5\ttraining's l2: 1.54492e+08\tvalid_1's rmse: 15065.6\tvalid_1's l2: 2.26974e+08\n",
      "[260]\ttraining's rmse: 12306.8\ttraining's l2: 1.51458e+08\tvalid_1's rmse: 15008.6\tvalid_1's l2: 2.25257e+08\n",
      "[270]\ttraining's rmse: 12188.6\ttraining's l2: 1.48562e+08\tvalid_1's rmse: 14954.7\tvalid_1's l2: 2.23643e+08\n",
      "[280]\ttraining's rmse: 12076.9\ttraining's l2: 1.45852e+08\tvalid_1's rmse: 14916.1\tvalid_1's l2: 2.2249e+08\n",
      "[290]\ttraining's rmse: 11974.2\ttraining's l2: 1.43382e+08\tvalid_1's rmse: 14882.7\tvalid_1's l2: 2.21496e+08\n",
      "[300]\ttraining's rmse: 11879.7\ttraining's l2: 1.41128e+08\tvalid_1's rmse: 14840.9\tvalid_1's l2: 2.20253e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[310]\ttraining's rmse: 11789.3\ttraining's l2: 1.38989e+08\tvalid_1's rmse: 14813.7\tvalid_1's l2: 2.19445e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[320]\ttraining's rmse: 11694.9\ttraining's l2: 1.36771e+08\tvalid_1's rmse: 14760.1\tvalid_1's l2: 2.17859e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[330]\ttraining's rmse: 11620.6\ttraining's l2: 1.35039e+08\tvalid_1's rmse: 14727.5\tvalid_1's l2: 2.16899e+08\n",
      "[340]\ttraining's rmse: 11538.8\ttraining's l2: 1.33144e+08\tvalid_1's rmse: 14688.9\tvalid_1's l2: 2.15763e+08\n",
      "[350]\ttraining's rmse: 11454.9\ttraining's l2: 1.31216e+08\tvalid_1's rmse: 14649.9\tvalid_1's l2: 2.14621e+08\n",
      "[360]\ttraining's rmse: 11367.2\ttraining's l2: 1.29214e+08\tvalid_1's rmse: 14628.5\tvalid_1's l2: 2.13994e+08\n",
      "[370]\ttraining's rmse: 11287.7\ttraining's l2: 1.27412e+08\tvalid_1's rmse: 14596.4\tvalid_1's l2: 2.13055e+08\n",
      "[380]\ttraining's rmse: 11215\ttraining's l2: 1.25776e+08\tvalid_1's rmse: 14565.4\tvalid_1's l2: 2.12151e+08\n",
      "[390]\ttraining's rmse: 11150\ttraining's l2: 1.24322e+08\tvalid_1's rmse: 14543.2\tvalid_1's l2: 2.11505e+08\n",
      "[400]\ttraining's rmse: 11076.9\ttraining's l2: 1.22697e+08\tvalid_1's rmse: 14509.6\tvalid_1's l2: 2.10529e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[410]\ttraining's rmse: 11013.6\ttraining's l2: 1.21299e+08\tvalid_1's rmse: 14487.9\tvalid_1's l2: 2.099e+08\n",
      "[420]\ttraining's rmse: 10945.2\ttraining's l2: 1.19797e+08\tvalid_1's rmse: 14465.7\tvalid_1's l2: 2.09257e+08\n",
      "[430]\ttraining's rmse: 10878.4\ttraining's l2: 1.1834e+08\tvalid_1's rmse: 14459.6\tvalid_1's l2: 2.09079e+08\n",
      "[440]\ttraining's rmse: 10816.5\ttraining's l2: 1.16998e+08\tvalid_1's rmse: 14444.5\tvalid_1's l2: 2.08644e+08\n",
      "[450]\ttraining's rmse: 10738.7\ttraining's l2: 1.15319e+08\tvalid_1's rmse: 14420.9\tvalid_1's l2: 2.07961e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[460]\ttraining's rmse: 10690.2\ttraining's l2: 1.14281e+08\tvalid_1's rmse: 14402.6\tvalid_1's l2: 2.07434e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[470]\ttraining's rmse: 10631.4\ttraining's l2: 1.13026e+08\tvalid_1's rmse: 14384.6\tvalid_1's l2: 2.06917e+08\n",
      "[480]\ttraining's rmse: 10572\ttraining's l2: 1.11767e+08\tvalid_1's rmse: 14378.3\tvalid_1's l2: 2.06736e+08\n",
      "[490]\ttraining's rmse: 10516.9\ttraining's l2: 1.10605e+08\tvalid_1's rmse: 14353.1\tvalid_1's l2: 2.06011e+08\n",
      "[500]\ttraining's rmse: 10468.3\ttraining's l2: 1.09585e+08\tvalid_1's rmse: 14344.1\tvalid_1's l2: 2.05753e+08\n",
      "[510]\ttraining's rmse: 10402\ttraining's l2: 1.08201e+08\tvalid_1's rmse: 14317.9\tvalid_1's l2: 2.05001e+08\n",
      "[520]\ttraining's rmse: 10350.2\ttraining's l2: 1.07126e+08\tvalid_1's rmse: 14309\tvalid_1's l2: 2.04746e+08\n",
      "[530]\ttraining's rmse: 10296.5\ttraining's l2: 1.06018e+08\tvalid_1's rmse: 14303\tvalid_1's l2: 2.04575e+08\n",
      "[540]\ttraining's rmse: 10237.4\ttraining's l2: 1.04804e+08\tvalid_1's rmse: 14288.9\tvalid_1's l2: 2.04173e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[550]\ttraining's rmse: 10185.7\ttraining's l2: 1.03749e+08\tvalid_1's rmse: 14285.9\tvalid_1's l2: 2.04087e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[560]\ttraining's rmse: 10142\ttraining's l2: 1.02861e+08\tvalid_1's rmse: 14274.9\tvalid_1's l2: 2.03773e+08\n",
      "[570]\ttraining's rmse: 10093\ttraining's l2: 1.01869e+08\tvalid_1's rmse: 14259.5\tvalid_1's l2: 2.03335e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\ttraining's rmse: 10052.8\ttraining's l2: 1.01059e+08\tvalid_1's rmse: 14255.9\tvalid_1's l2: 2.03229e+08\n",
      "[590]\ttraining's rmse: 10011.4\ttraining's l2: 1.00229e+08\tvalid_1's rmse: 14241.8\tvalid_1's l2: 2.0283e+08\n",
      "[600]\ttraining's rmse: 9975.56\ttraining's l2: 9.95118e+07\tvalid_1's rmse: 14240.5\tvalid_1's l2: 2.02791e+08\n",
      "[610]\ttraining's rmse: 9921.3\ttraining's l2: 9.84321e+07\tvalid_1's rmse: 14230.3\tvalid_1's l2: 2.025e+08\n",
      "[620]\ttraining's rmse: 9869.31\ttraining's l2: 9.74034e+07\tvalid_1's rmse: 14223.8\tvalid_1's l2: 2.02318e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[630]\ttraining's rmse: 9829.79\ttraining's l2: 9.66248e+07\tvalid_1's rmse: 14212.2\tvalid_1's l2: 2.01988e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[640]\ttraining's rmse: 9790.22\ttraining's l2: 9.58485e+07\tvalid_1's rmse: 14207.9\tvalid_1's l2: 2.01864e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[650]\ttraining's rmse: 9743.02\ttraining's l2: 9.49264e+07\tvalid_1's rmse: 14207.7\tvalid_1's l2: 2.0186e+08\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's rmse: 9779.61\ttraining's l2: 9.56407e+07\tvalid_1's rmse: 14205.2\tvalid_1's l2: 2.01788e+08\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1620\n",
      "[LightGBM] [Info] Number of data points in the train set: 58303, number of used features: 13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Start training from score 102834.860402\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's rmse: 38413.3\ttraining's l2: 1.47559e+09\tvalid_1's rmse: 38963.5\tvalid_1's l2: 1.51815e+09\n",
      "[20]\ttraining's rmse: 24932.1\ttraining's l2: 6.21609e+08\tvalid_1's rmse: 25952.9\tvalid_1's l2: 6.73554e+08\n",
      "[30]\ttraining's rmse: 20567.1\ttraining's l2: 4.23007e+08\tvalid_1's rmse: 22027.2\tvalid_1's l2: 4.85197e+08\n",
      "[40]\ttraining's rmse: 18670.7\ttraining's l2: 3.48595e+08\tvalid_1's rmse: 20370.7\tvalid_1's l2: 4.14964e+08\n",
      "[50]\ttraining's rmse: 17570.4\ttraining's l2: 3.0872e+08\tvalid_1's rmse: 19399.3\tvalid_1's l2: 3.76333e+08\n",
      "[60]\ttraining's rmse: 16789\ttraining's l2: 2.81872e+08\tvalid_1's rmse: 18810.6\tvalid_1's l2: 3.5384e+08\n",
      "[70]\ttraining's rmse: 16153.8\ttraining's l2: 2.60946e+08\tvalid_1's rmse: 18357.3\tvalid_1's l2: 3.36991e+08\n",
      "[80]\ttraining's rmse: 15673.1\ttraining's l2: 2.45645e+08\tvalid_1's rmse: 18047.8\tvalid_1's l2: 3.25723e+08\n",
      "[90]\ttraining's rmse: 15303.6\ttraining's l2: 2.342e+08\tvalid_1's rmse: 17813.4\tvalid_1's l2: 3.17317e+08\n",
      "[100]\ttraining's rmse: 14975\ttraining's l2: 2.24252e+08\tvalid_1's rmse: 17598.1\tvalid_1's l2: 3.09693e+08\n",
      "[110]\ttraining's rmse: 14665.8\ttraining's l2: 2.15085e+08\tvalid_1's rmse: 17433.2\tvalid_1's l2: 3.03917e+08\n",
      "[120]\ttraining's rmse: 14367.3\ttraining's l2: 2.0642e+08\tvalid_1's rmse: 17263.6\tvalid_1's l2: 2.98033e+08\n",
      "[130]\ttraining's rmse: 14142.7\ttraining's l2: 2.00015e+08\tvalid_1's rmse: 17150.8\tvalid_1's l2: 2.94151e+08\n",
      "[140]\ttraining's rmse: 13901.1\ttraining's l2: 1.9324e+08\tvalid_1's rmse: 17025.2\tvalid_1's l2: 2.89858e+08\n",
      "[150]\ttraining's rmse: 13704.4\ttraining's l2: 1.87812e+08\tvalid_1's rmse: 16940.1\tvalid_1's l2: 2.86966e+08\n",
      "[160]\ttraining's rmse: 13506.2\ttraining's l2: 1.82418e+08\tvalid_1's rmse: 16858\tvalid_1's l2: 2.84194e+08\n",
      "[170]\ttraining's rmse: 13317.4\ttraining's l2: 1.77353e+08\tvalid_1's rmse: 16785.2\tvalid_1's l2: 2.81743e+08\n",
      "[180]\ttraining's rmse: 13139\ttraining's l2: 1.72633e+08\tvalid_1's rmse: 16671.2\tvalid_1's l2: 2.77929e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[190]\ttraining's rmse: 12986.9\ttraining's l2: 1.6866e+08\tvalid_1's rmse: 16615.2\tvalid_1's l2: 2.76063e+08\n",
      "[200]\ttraining's rmse: 12799.3\ttraining's l2: 1.63822e+08\tvalid_1's rmse: 16546.3\tvalid_1's l2: 2.73781e+08\n",
      "[210]\ttraining's rmse: 12669.4\ttraining's l2: 1.60514e+08\tvalid_1's rmse: 16496.7\tvalid_1's l2: 2.72141e+08\n",
      "[220]\ttraining's rmse: 12529.6\ttraining's l2: 1.56991e+08\tvalid_1's rmse: 16463.6\tvalid_1's l2: 2.71049e+08\n",
      "[230]\ttraining's rmse: 12411.1\ttraining's l2: 1.54035e+08\tvalid_1's rmse: 16416\tvalid_1's l2: 2.69485e+08\n",
      "[240]\ttraining's rmse: 12276.3\ttraining's l2: 1.50708e+08\tvalid_1's rmse: 16361.3\tvalid_1's l2: 2.67692e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\ttraining's rmse: 12170.8\ttraining's l2: 1.48128e+08\tvalid_1's rmse: 16328.5\tvalid_1's l2: 2.66621e+08\n",
      "[260]\ttraining's rmse: 12070.5\ttraining's l2: 1.45697e+08\tvalid_1's rmse: 16277.9\tvalid_1's l2: 2.6497e+08\n",
      "[270]\ttraining's rmse: 11948.2\ttraining's l2: 1.42759e+08\tvalid_1's rmse: 16219.1\tvalid_1's l2: 2.63058e+08\n",
      "[280]\ttraining's rmse: 11852.1\ttraining's l2: 1.40472e+08\tvalid_1's rmse: 16192.8\tvalid_1's l2: 2.62206e+08\n",
      "[290]\ttraining's rmse: 11755.9\ttraining's l2: 1.38201e+08\tvalid_1's rmse: 16167.4\tvalid_1's l2: 2.61385e+08\n",
      "[300]\ttraining's rmse: 11665.4\ttraining's l2: 1.36082e+08\tvalid_1's rmse: 16137.2\tvalid_1's l2: 2.6041e+08\n",
      "[310]\ttraining's rmse: 11587.8\ttraining's l2: 1.34276e+08\tvalid_1's rmse: 16104.2\tvalid_1's l2: 2.59346e+08\n",
      "[320]\ttraining's rmse: 11502.5\ttraining's l2: 1.32308e+08\tvalid_1's rmse: 16077.6\tvalid_1's l2: 2.58489e+08\n",
      "[330]\ttraining's rmse: 11426.4\ttraining's l2: 1.30562e+08\tvalid_1's rmse: 16063.8\tvalid_1's l2: 2.58047e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[340]\ttraining's rmse: 11346.4\ttraining's l2: 1.2874e+08\tvalid_1's rmse: 16020.9\tvalid_1's l2: 2.56668e+08\n",
      "[350]\ttraining's rmse: 11268.1\ttraining's l2: 1.26971e+08\tvalid_1's rmse: 16003.1\tvalid_1's l2: 2.56098e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[360]\ttraining's rmse: 11205.6\ttraining's l2: 1.25566e+08\tvalid_1's rmse: 15978.4\tvalid_1's l2: 2.5531e+08\n",
      "[370]\ttraining's rmse: 11131.3\ttraining's l2: 1.23906e+08\tvalid_1's rmse: 15933.2\tvalid_1's l2: 2.53868e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[380]\ttraining's rmse: 11055.6\ttraining's l2: 1.22226e+08\tvalid_1's rmse: 15898.5\tvalid_1's l2: 2.52763e+08\n",
      "[390]\ttraining's rmse: 10981\ttraining's l2: 1.20582e+08\tvalid_1's rmse: 15875.6\tvalid_1's l2: 2.52036e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's rmse: 10913.6\ttraining's l2: 1.19107e+08\tvalid_1's rmse: 15859.8\tvalid_1's l2: 2.51533e+08\n",
      "[410]\ttraining's rmse: 10849.1\ttraining's l2: 1.17703e+08\tvalid_1's rmse: 15823.8\tvalid_1's l2: 2.50392e+08\n",
      "[420]\ttraining's rmse: 10786.2\ttraining's l2: 1.16342e+08\tvalid_1's rmse: 15800.3\tvalid_1's l2: 2.4965e+08\n",
      "[430]\ttraining's rmse: 10720.4\ttraining's l2: 1.14927e+08\tvalid_1's rmse: 15786.6\tvalid_1's l2: 2.49217e+08\n",
      "[440]\ttraining's rmse: 10657.7\ttraining's l2: 1.13587e+08\tvalid_1's rmse: 15756.8\tvalid_1's l2: 2.48278e+08\n",
      "[450]\ttraining's rmse: 10598.9\ttraining's l2: 1.12336e+08\tvalid_1's rmse: 15723.2\tvalid_1's l2: 2.47219e+08\n",
      "[460]\ttraining's rmse: 10536.4\ttraining's l2: 1.11016e+08\tvalid_1's rmse: 15701.5\tvalid_1's l2: 2.46537e+08\n",
      "[470]\ttraining's rmse: 10473.8\ttraining's l2: 1.09701e+08\tvalid_1's rmse: 15682.5\tvalid_1's l2: 2.45941e+08\n",
      "[480]\ttraining's rmse: 10427.1\ttraining's l2: 1.08724e+08\tvalid_1's rmse: 15678.3\tvalid_1's l2: 2.45809e+08\n",
      "[490]\ttraining's rmse: 10373.3\ttraining's l2: 1.07605e+08\tvalid_1's rmse: 15669.6\tvalid_1's l2: 2.45538e+08\n",
      "[500]\ttraining's rmse: 10316.9\ttraining's l2: 1.06439e+08\tvalid_1's rmse: 15651.1\tvalid_1's l2: 2.44958e+08\n",
      "[510]\ttraining's rmse: 10270.1\ttraining's l2: 1.05475e+08\tvalid_1's rmse: 15636\tvalid_1's l2: 2.44484e+08\n",
      "[520]\ttraining's rmse: 10217.9\ttraining's l2: 1.04405e+08\tvalid_1's rmse: 15634\tvalid_1's l2: 2.44423e+08\n",
      "[530]\ttraining's rmse: 10166.9\ttraining's l2: 1.03366e+08\tvalid_1's rmse: 15619.1\tvalid_1's l2: 2.43956e+08\n",
      "[540]\ttraining's rmse: 10108.3\ttraining's l2: 1.02178e+08\tvalid_1's rmse: 15580.9\tvalid_1's l2: 2.42765e+08\n",
      "[550]\ttraining's rmse: 10055.2\ttraining's l2: 1.01107e+08\tvalid_1's rmse: 15576.9\tvalid_1's l2: 2.42639e+08\n",
      "[560]\ttraining's rmse: 9999.8\ttraining's l2: 9.99961e+07\tvalid_1's rmse: 15563.1\tvalid_1's l2: 2.42211e+08\n",
      "[570]\ttraining's rmse: 9953.87\ttraining's l2: 9.90795e+07\tvalid_1's rmse: 15558\tvalid_1's l2: 2.4205e+08\n",
      "[580]\ttraining's rmse: 9906.58\ttraining's l2: 9.81404e+07\tvalid_1's rmse: 15550.1\tvalid_1's l2: 2.41805e+08\n",
      "[590]\ttraining's rmse: 9861.37\ttraining's l2: 9.72466e+07\tvalid_1's rmse: 15527.8\tvalid_1's l2: 2.41114e+08\n",
      "[600]\ttraining's rmse: 9822.52\ttraining's l2: 9.64819e+07\tvalid_1's rmse: 15507.8\tvalid_1's l2: 2.40492e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[610]\ttraining's rmse: 9781.97\ttraining's l2: 9.56869e+07\tvalid_1's rmse: 15502.3\tvalid_1's l2: 2.40323e+08\n",
      "[620]\ttraining's rmse: 9744.21\ttraining's l2: 9.49496e+07\tvalid_1's rmse: 15485.7\tvalid_1's l2: 2.39808e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[630]\ttraining's rmse: 9708.72\ttraining's l2: 9.42593e+07\tvalid_1's rmse: 15473.3\tvalid_1's l2: 2.39421e+08\n",
      "[640]\ttraining's rmse: 9666.73\ttraining's l2: 9.34457e+07\tvalid_1's rmse: 15455.2\tvalid_1's l2: 2.38863e+08\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[650]\ttraining's rmse: 9628.56\ttraining's l2: 9.27092e+07\tvalid_1's rmse: 15455.2\tvalid_1's l2: 2.38864e+08\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's rmse: 9659.57\ttraining's l2: 9.33073e+07\tvalid_1's rmse: 15452\tvalid_1's l2: 2.38763e+08\n"
     ]
    }
   ],
   "source": [
    "gbm_transfer_list = []\n",
    "for i, random_state in enumerate([0, 1, 42, 2023, 2024]):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    gbm = gbm_list[i]\n",
    "\n",
    "    gbm.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=10),\n",
    "                    lgb.log_evaluation(period=10, show_stdv=True)])\n",
    "    \n",
    "    gbm_transfer_list.append(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.272000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.050738e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.456380e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.815000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.215725e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.556700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.241328e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.165343e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  9.272000e+03\n",
       "mean   1.050738e+05\n",
       "std    7.456380e+04\n",
       "min    2.815000e+03\n",
       "25%    6.215725e+04\n",
       "50%    8.556700e+04\n",
       "75%    1.241328e+05\n",
       "max    1.165343e+06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.272000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.050891e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.417295e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.919000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.194375e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.545900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.245735e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.080015e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  9.272000e+03\n",
       "mean   1.050891e+05\n",
       "std    7.417295e+04\n",
       "min    2.919000e+03\n",
       "25%    6.194375e+04\n",
       "50%    8.545900e+04\n",
       "75%    1.245735e+05\n",
       "max    1.080015e+06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.272000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.049633e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.456558e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.052000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.200850e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.588350e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.236122e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.177325e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  9.272000e+03\n",
       "mean   1.049633e+05\n",
       "std    7.456558e+04\n",
       "min    3.052000e+03\n",
       "25%    6.200850e+04\n",
       "50%    8.588350e+04\n",
       "75%    1.236122e+05\n",
       "max    1.177325e+06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.272000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.049521e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.426768e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.898000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.216650e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.537350e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.240122e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.182063e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  9.272000e+03\n",
       "mean   1.049521e+05\n",
       "std    7.426768e+04\n",
       "min    3.898000e+03\n",
       "25%    6.216650e+04\n",
       "50%    8.537350e+04\n",
       "75%    1.240122e+05\n",
       "max    1.182063e+06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.272000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.049797e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.500050e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.987000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.203375e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.551650e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.243118e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.186502e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  9.272000e+03\n",
       "mean   1.049797e+05\n",
       "std    7.500050e+04\n",
       "min    2.987000e+03\n",
       "25%    6.203375e+04\n",
       "50%    8.551650e+04\n",
       "75%    1.243118e+05\n",
       "max    1.186502e+06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in gbm_transfer_list:\n",
    "    real_test_pred = e.predict(X_test)\n",
    "    preds_df = pd.DataFrame(real_test_pred.astype(int), columns=[\"target\"])\n",
    "    display(preds_df.describe())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_test_pred = gbm_transfer_list[-1].predict(X_test)\n",
    "preds_df = pd.DataFrame(real_test_pred.astype(int), columns=[\"target\"])\n",
    "preds_df.to_csv('transfer_learning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
